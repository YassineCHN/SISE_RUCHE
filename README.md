# ğŸ RUCHE
Projet NLP & Text Mining â€“ Master 2 SISE (2025â€“2026) 

### Application de cherche d'emplois

<p align="center">
  <img src="streamlit/static/Logo3.png" alt="RUCHE" width="280">
</p>

![Python](https://img.shields.io/badge/Python-3.11+-3776AB?style=for-the-badge&logo=python&logoColor=white)
![SQL](https://img.shields.io/badge/SQL-DuckDB-2E86C1?style=for-the-badge&logo=databricks&logoColor=white)
![MongoDB](https://img.shields.io/badge/MongoDB-Data%20Lake-47A248?style=for-the-badge&logo=mongodb&logoColor=white)
![MotherDuck](https://img.shields.io/badge/MotherDuck-DuckDB%20Cloud-FFD43B?style=for-the-badge&logo=duckdb&logoColor=black)
![Streamlit](https://img.shields.io/badge/Streamlit-1.30+-FF4B4B?style=for-the-badge&logo=streamlit&logoColor=white)
![Plotly](https://img.shields.io/badge/Plotly-Interactive%20Viz-3F4F75?style=for-the-badge&logo=plotly&logoColor=white)
![Folium](https://img.shields.io/badge/Folium-Maps-77B829?style=for-the-badge)
![Selenium](https://img.shields.io/badge/Selenium-Web%20Scraping-43B02A?style=for-the-badge&logo=selenium&logoColor=white)
![BeautifulSoup](https://img.shields.io/badge/BeautifulSoup-HTML%20Parsing-59666C?style=for-the-badge)
![Docker](https://img.shields.io/badge/Docker-Containerization-2496ED?style=for-the-badge&logo=docker&logoColor=white)
![Mistral](https://img.shields.io/badge/Mistral-LLM%20API-FFB703?style=for-the-badge)


## PrÃ©sentation du projet

**RUCHE** est une plateforme dâ€™analyse du marchÃ© de lâ€™emploi **Data Science & Intelligence Artificielle** en France.  
Elle combine **web scraping**, **NLP**, **machine learning**, **data warehousing** et **visualisation interactive** pour proposer :

-  **Une recherche sÃ©mantique intelligente** dâ€™offres dâ€™emploi  
-  **Une cartographie gÃ©ographique interactive** du marchÃ© de lâ€™emploi  
-  **Des analyses avancÃ©es** sur les salaires, les compÃ©tences et les tendances du marchÃ©
-  **Enregistrement de nouvelles offres** pour les utilisateurs de l'application

Le systÃ¨me repose sur une **architecture end-to-end**, depuis la collecte des donnÃ©es jusquâ€™Ã  leur exploitation analytique au sein dâ€™une application **Streamlit**.

---

## ğŸ§  Objectifs du projet

Le projet RUCHE sâ€™inscrit dans le cadre du module **NLP & Text Mining** du Master 2 SISE et rÃ©pond aux objectifs pÃ©dagogiques suivants :

- ğŸ“¥ **Constituer un corpus dâ€™offres dâ€™emploi**
  - Extraction automatisÃ©e dâ€™annonces issues de plateformes dâ€™emploi accessibles en ligne  
    (France Travail, APEC, JobTeaser, Choisir le Service Public, etc.)
  - Collecte rÃ©alisÃ©e via des techniques de **web scraping** (BeautifulSoup, Selenium) et des **API** lorsque disponibles
  - Exploitation des champs structurÃ©s lorsquâ€™ils sont disponibles  
    *(titre, missions, compÃ©tences, profil, rÃ©munÃ©ration, localisation, type de contratâ€¦)*
  - Analyse du **corps textuel complet** lorsque la structure est absente ou hÃ©tÃ©rogÃ¨ne
  - Focalisation sur les **mÃ©tiers et compÃ©tences liÃ©s Ã  la Data Science et Ã  lâ€™Intelligence Artificielle**
  - Stocker sur MongoDB (Base NoSql) dans diffÃ©rentes collections les offres scrapper
  - 6000 offres collectÃ©s 

- ğŸ—„ï¸ **Mettre en place un entrepÃ´t de donnÃ©es**
  - CrÃ©action d'une pipeline d'ETL pour **extraire** nos offre de MongoDb, les **transformer** et les **charger** dans une BDD relationnel sur MotherDuckdb
  - ModÃ©lisation sous forme de **schÃ©ma en Ã©toile** (table de faits et dimensions)
  - Stockage dans un **SGBD libre** (DuckDB via MotherDuck)
  - Connexion directe entre lâ€™application et la base de donnÃ©es analytique
  - ~4000 offres aprÃ¨s nettoyages stocker sur MotherDuck et DuckDB
    
- ğŸ§  **Appliquer des mÃ©thodes avancÃ©es de NLP et de Machine Learning**
  - Filtrage automatique des offres non pertinentes (hors data / IA)
  - Vectorisation sÃ©mantique des annonces
  - Recherche par similaritÃ© en langage naturel
  - Analyses interprÃ©tables et lisibles, y compris lors de lâ€™usage de modÃ¨les de langage (LLM)

- ğŸŒ **DÃ©velopper une application web interactive**
  - Application Python basÃ©e sur **Streamlit**
  - Interface dÃ©diÃ©e Ã  lâ€™exploration, la recherche et lâ€™analyse du corpus
  - Visualisations interactives (cartes, graphiques dynamiques, clustering)

- ğŸ—ºï¸ **IntÃ©grer une dimension gÃ©ographique**
  - Analyse territoriale Ã  lâ€™Ã©chelle des villes, dÃ©partements et rÃ©gions
  - ReprÃ©sentations cartographiques interactives

- â• **Permettre lâ€™ajout dynamique de nouvelles offres**
  - Ajout manuel ou semi-automatisÃ© dâ€™annonces (LLM - Mistral)
  - MÃ©canismes de **dÃ©tection de doublons** pour prÃ©server la qualitÃ© du corpus

- ğŸš¢ **Garantir la reproductibilitÃ© et le dÃ©ploiement**
  - DÃ©ploiement de lâ€™ensemble du systÃ¨me via une **image Docker**
  - Lâ€™utilisateur peut lancer lâ€™application sans configuration complexe

---

## ğŸ—ï¸ Architecture globale

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Web Scraping â”‚ â†’  â”‚      MongoDB       â”‚ â†’  â”‚  ETL & Normalisation â”‚ â†’  â”‚        MotherDuck        â”‚ â†’  â”‚        Streamlit      â”‚
â”‚ APIs/Crawlers â”‚    â”‚ BDD NSql  (JSON)   â”‚    â”‚ Nettoyage & Enrich.  â”‚    â”‚ Data Warehouse Ã©toile   â”‚    â”‚ Recherche & Analyses  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸŒ Sources de donnÃ©es

Quatre plateformes majeures ont Ã©tÃ© exploitÃ©es :

- **France Travail**  
  API officielle, OAuth2, scraping parallÃ¨le
- **APEC**  
  Selenium + BeautifulSoup, extraction structurÃ©e offline
- **JobTeaser**  
  Anti-bot, scraping React, filtrage prÃ©coce
- **Choisir le Service Public**  
  Scraping + extraction structurÃ©e assistÃ©e par LLM (Mistral)

Les donnÃ©es brutes sont stockÃ©es en **MongoDB Atlas** (NoSQL) au format **JSON**.

---

## ğŸ—„ï¸ Data Warehouse â€“ MotherDuck

Le data warehouse repose sur **MotherDuck (DuckDB cloud)** avec :

- **SchÃ©ma en Ã©toile**
- **Table de faits** : `f_offre`
- **Dimensions** : `d_date`, `d_contrat`, `d_localisation`, `h_region`

--- 

## ğŸ¤– NLP & Machine Learning

### ğŸ” Filtrage Data / Non-Data

Approche hybride :
- rÃ¨gles expertes (regex whitelist / blacklist)
- **TF-IDF + rÃ©gression logistique**

RÃ©sultats :
- **F1-score : 0.978**
- **ROC-AUC : 0.996**
- **+67 %** dâ€™offres data rÃ©cupÃ©rÃ©es par rapport aux regex seules

---

### ğŸ” Recherche sÃ©mantique
- ModÃ¨le : `sentence-transformers/paraphrase-multilingual-mpnet-base-v2`
- RequÃªtes en **langage naturel**
- SimilaritÃ© cosinus calculÃ©e **cÃ´tÃ© base** (DuckDB)

---

## ğŸ–¥ï¸ Application Streamlit

Application **multi-pages** :
- Recherche sÃ©mantique, par mot clÃ© et filtre
- Cartographie interactive (Folium + clustering)
- Tableaux de bord analytiques (Plotly)
- Ajout manuel dâ€™offres et Chatbot LLM (Mistral) pour la structuration dâ€™offres
- Clustering sÃ©mantique (UMAP + HDBSCAN)
- Graphe de co-occurrences des compÃ©tences

ğŸ”’ Connexion sÃ©curisÃ©e Ã  MotherDuck via token  

---



## Architecture du Projet 

```
RUCHE/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ backup_job_market.duckdb
â”‚   â””â”€â”€ local.duckdb
â”‚
â”œâ”€â”€ scraping/
â”‚   â”œâ”€â”€ francetravail/
â”‚   â”œâ”€â”€ apec/
â”‚   â”œâ”€â”€ jobteaser/
â”‚   â””â”€â”€ service_public/
â”‚
â”œâ”€â”€ mongodb/
â”‚   â”œâ”€â”€ main_mongo.py
â”‚   â”œâ”€â”€ reference_apec.py
â”‚   â”œâ”€â”€ mongodb_load_jobteaser.py
â”‚   â””â”€â”€ mongodb_utils.py
â”‚
â”œâ”€â”€ etl/
â”‚   â”œâ”€â”€ cleanX.py #Tout les "clean" fpnction de nettoyage de donnÃ©e
â”‚   â”œâ”€â”€ config_etl.py
â”‚   â”œâ”€â”€ etl_utils.py
â”‚   â”œâ”€â”€ etl_vectorization.py
â”‚   â”œâ”€â”€ tfidf_ml_data_filter.py
â”‚   â”œâ”€â”€ geolocation_enrichment.py # API pour longÃ©tude et latitude 
â”‚   â””â”€â”€ etl_motherduck.py
â”‚
â”œâ”€â”€ streamlit_app/
â”‚   â”œâ”€â”€ 1_home_page.py
â”‚   â”œâ”€â”€ 2_cartographie.py
â”‚   â”œâ”€â”€ 3_visualisation.py
â”‚   â”œâ”€â”€ 4_add_offers.py
â”‚   â”œâ”€â”€ 5_clustering.py
â”‚   â”œâ”€â”€ 6_graphe_competences.py
â”‚   â”œâ”€â”€ 7_llm.py
â”‚   â”œâ”€â”€ 8_about.py
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ static/ # Logo & images
â”‚   â”œâ”€â”€ db/
â”‚   â””â”€â”€ analyse_competences/
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ Rapport.md
â”‚   â”œâ”€â”€ notice_france_travail_scraper.md
â”‚   â”œâ”€â”€ notice_TFIDF_ML_filtre_data_nondata.md
â”‚   â””â”€â”€ notice_moteur_recherche_semantique.md
â”‚
â”œâ”€â”€ duck_to_mother.py
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ test_connexion_duckdb.py
â”œâ”€â”€ test_creation_duckdb.py
â””â”€â”€ README.md

```
--- 

## ğŸš€ Lancer lâ€™application

1. **Installer les dÃ©pendances:**
```bash
pip install -r requirements_mongodo_ftscraper.txt
```

2. **Configurer `.env` file:**
```env
export MOTHERDUCK_TOKEN=...
export MISTRAL_API_KEY=...
```

3. **Lancer Streamlit**
```bash
streamlit run app.py
```

--- 
## ğŸ“š Ressources associÃ©es

- ğŸ“„ **Rapport acadÃ©mique (PDF)**  : [Projet NLP & Text Mining â€“ Rapport RUCHE (Groupe 6)](documentation/SISE_NLP_Text_Mining_Rapport_Groupe6_RUCHE.pdf)
- ğŸ“˜ **Notice technique â€“ Filtrage ML Data / Non-Data**  : [TF-IDF & RÃ©gression logistique](documentation/notice_TFIDF_ML_filtre_data_nondata.md)
- ğŸ“˜ **Notice technique â€“ Scraper France Travail**  : [API & Web Scraping France Travail](documentation/notice_france_travail_scraper.md)
- ğŸ“˜ **Notice technique â€“ Moteur de recherche sÃ©mantique**  : [Recherche vectorielle & similaritÃ© cosinus](documentation/notice_moteur_recherche_semantique.md)



## ğŸ‘¥ Ã‰quipe

- Romain Buono
-  Yassine Cheniour
- MilÃ©na Gordien-Piquet
- Anne-Camille Vial

#### ğŸ“ Master 2 SISE â€“ UniversitÃ© Lyon 2
#### ğŸ‘¨â€ğŸ« Encadrant : M. Ricco Rakotomalala

---
