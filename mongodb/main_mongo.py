"""
Script pour importer des donn√©es JSON APEC dans MongoDB Atlas
Collection: RUCHE_datalake > apec_raw
Version corrig√©e utilisant reference_apec comme identifiant unique
"""

import json
import os
from typing import List, Dict, Any
from pymongo import MongoClient
from dotenv import load_dotenv
import certifi
from collections import Counter

# Charger les variables d'environnement
load_dotenv()
MONGO_URI = os.getenv("MONGO_URI")
DB_NAME = "RUCHE_datalake"


def analyze_json_structure(file_path: str) -> Dict[str, Any]:
    """
    Analyser la structure du fichier JSON et d√©tecter les probl√®mes
    
    Returns:
        Dictionnaire avec statistiques d'analyse
    """
    print(f"\nüîç ANALYSE DU FICHIER JSON")
    print("=" * 80)
    
    if not os.path.exists(file_path):
        return {"error": f"Fichier introuvable: {file_path}"}
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # Convertir en liste si n√©cessaire
        if isinstance(data, dict):
            data = [data]
        
        # Analyser les champs
        refs = []
        ids = []
        missing_ref = 0
        missing_id = 0
        
        for i, doc in enumerate(data):
            if not isinstance(doc, dict):
                continue
            
            # V√©rifier reference_apec
            if 'reference_apec' in doc:
                refs.append(doc['reference_apec'])
            else:
                missing_ref += 1
            
            # V√©rifier id
            if 'id' in doc:
                ids.append(doc['id'])
            else:
                missing_id += 1
        
        # Compter les doublons
        ref_counts = Counter(refs)
        id_counts = Counter(ids)
        
        ref_duplicates = {k: v for k, v in ref_counts.items() if v > 1}
        id_duplicates = {k: v for k, v in id_counts.items() if v > 1}
        
        stats = {
            "total_documents": len(data),
            "with_reference_apec": len(refs),
            "with_id": len(ids),
            "missing_reference_apec": missing_ref,
            "missing_id": missing_id,
            "unique_references": len(set(refs)),
            "unique_ids": len(set(ids)),
            "ref_duplicates": len(ref_duplicates),
            "id_duplicates": len(id_duplicates)
        }
        
        # Affichage
        print(f"\nüìä STRUCTURE DU FICHIER :")
        print(f"   - Total de documents : {stats['total_documents']}")
        print(f"   - Documents avec 'reference_apec' : {stats['with_reference_apec']}")
        print(f"   - Documents avec 'id' : {stats['with_id']}")
        print(f"   - References APEC uniques : {stats['unique_references']}")
        print(f"   - IDs uniques : {stats['unique_ids']}")
        
        if stats['missing_reference_apec'] > 0:
            print(f"\n‚ö†Ô∏è  {stats['missing_reference_apec']} documents SANS 'reference_apec'")
        
        if stats['ref_duplicates'] > 0:
            print(f"\n‚ö†Ô∏è  DOUBLONS 'reference_apec' D√âTECT√âS :")
            print(f"   {stats['ref_duplicates']} r√©f√©rences en double")
            for ref, count in list(ref_duplicates.items())[:5]:
                print(f"   ‚Ä¢ {ref} : {count} fois")
        
        if stats['id_duplicates'] > 0:
            print(f"\n‚ö†Ô∏è  DOUBLONS 'id' D√âTECT√âS :")
            print(f"   {stats['id_duplicates']} IDs en double")
            for doc_id, count in list(id_duplicates.items())[:5]:
                print(f"   ‚Ä¢ {doc_id} : {count} fois")
        
        print("=" * 80)
        
        return stats
        
    except Exception as e:
        return {"error": str(e)}


def load_and_prepare_json(file_path: str) -> List[Dict[str, Any]]:
    """
    Charger le fichier JSON et pr√©parer les documents
    Copie reference_apec vers id pour chaque document
    
    Returns:
        Liste de documents pr√©par√©s
    """
    print(f"\nüìÇ CHARGEMENT DU FICHIER")
    print("=" * 80)
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # Convertir en liste
        if isinstance(data, dict):
            data = [data]
        
        print(f"‚úì {len(data)} documents charg√©s")
        
        # Pr√©parer les documents
        print(f"\nüîß PR√âPARATION DES DOCUMENTS")
        print("   Copie de 'reference_apec' vers 'id'...")
        
        prepared = []
        missing_ref = 0
        duplicates_found = {}
        seen_refs = set()
        
        for i, doc in enumerate(data):
            if not isinstance(doc, dict):
                continue
            
            # V√©rifier reference_apec
            if 'reference_apec' not in doc:
                missing_ref += 1
                print(f"   ‚ö†Ô∏è  Document {i} sans 'reference_apec', ignor√©")
                continue
            
            ref = doc['reference_apec']
            
            # D√©tecter doublons dans le fichier
            if ref in seen_refs:
                if ref not in duplicates_found:
                    duplicates_found[ref] = 1
                duplicates_found[ref] += 1
                continue  # Ignorer le doublon
            
            # Copier reference_apec vers id
            doc['id'] = ref
            seen_refs.add(ref)
            prepared.append(doc)
        
        # Statistiques
        print(f"\n‚úì Documents pr√©par√©s : {len(prepared)}")
        if missing_ref > 0:
            print(f"‚ö†Ô∏è  Documents ignor√©s (sans reference_apec) : {missing_ref}")
        if duplicates_found:
            print(f"‚ö†Ô∏è  Doublons ignor√©s : {len(duplicates_found)}")
            for ref, count in list(duplicates_found.items())[:5]:
                print(f"   ‚Ä¢ {ref} : {count} fois")
        
        print("=" * 80)
        
        return prepared
        
    except Exception as e:
        print(f"‚úó ERREUR: {e}")
        return []


def import_to_apec_raw(
    json_file_path: str,
    mode: str = "insert",  # "insert" ou "upsert"
    analyze_first: bool = True
):
    """
    Importer des donn√©es JSON dans la collection apec_raw
    
    Args:
        json_file_path: Chemin vers le fichier JSON
        mode: "insert" (ignorer doublons) ou "upsert" (mettre √† jour)
        analyze_first: Analyser le fichier avant import
    """
    
    print("\n")
    print("=" * 80)
    print("IMPORT DE DONN√âES APEC DANS MONGODB ATLAS")
    print(f"Collection: {DB_NAME}.apec_raw")
    print(f"Mode: {mode.upper()}")
    print("=" * 80)
    
    # √âTAPE 0 : Analyse (optionnelle)
    if analyze_first:
        stats = analyze_json_structure(json_file_path)
        if "error" in stats:
            print(f"\n‚úó Erreur d'analyse: {stats['error']}")
            return
    
    # √âTAPE 1 : Charger et pr√©parer
    documents = load_and_prepare_json(json_file_path)
    
    if not documents:
        print("\n‚úó Aucune donn√©e √† importer!")
        return
    
    # √âTAPE 2 : Connexion MongoDB
    print(f"\nüîå CONNEXION √Ä MONGODB")
    print("=" * 80)
    
    try:
        client = MongoClient(MONGO_URI, tlsCAFile=certifi.where())
        client.admin.command('ping')
        print(f"‚úì Connect√© √† MongoDB Atlas")
        print(f"  Database: {DB_NAME}")
    except Exception as e:
        print(f"‚úó Erreur de connexion: {e}")
        print("  V√©rifiez MONGO_URI dans votre fichier .env")
        return
    
    # √âTAPE 3 : Acc√®s √† la collection
    try:
        db = client[DB_NAME]
        collection = db["apec_raw"]
        print(f"‚úì Collection: apec_raw")
    except Exception as e:
        print(f"‚úó Erreur d'acc√®s: {e}")
        client.close()
        return
    
    print("=" * 80)
    
    # √âTAPE 4 : Cr√©ation des index
    print(f"\nüîë CR√âATION DES INDEX")
    print("=" * 80)
    
    try:
        collection.create_index([("id", 1)], unique=True)
        print("‚úì Index unique sur 'id'")
        
        collection.create_index([("reference_apec", 1)], unique=True)
        print("‚úì Index unique sur 'reference_apec'")
    except Exception as e:
        print(f"‚ö†Ô∏è  Warning: {e}")
    
    print("=" * 80)
    
    # √âTAPE 5 : V√©rification des doublons en base
    print(f"\nüîç V√âRIFICATION DES DOUBLONS")
    print("=" * 80)
    
    try:
        doc_ids = [doc['id'] for doc in documents]
        existing_docs = list(collection.find(
            {"id": {"$in": doc_ids}},
            {"id": 1, "_id": 0}
        ))
        existing_ids = [doc['id'] for doc in existing_docs]
        new_ids = [id for id in doc_ids if id not in existing_ids]
        
        print(f"   - Documents √† importer : {len(doc_ids)}")
        print(f"   - D√©j√† en base : {len(existing_ids)}")
        print(f"   - Nouveaux : {len(new_ids)}")
        
        if len(existing_ids) > 0 and len(existing_ids) <= 5:
            print(f"\n   IDs d√©j√† pr√©sents :")
            for eid in existing_ids:
                print(f"   ‚Ä¢ {eid}")
    
    except Exception as e:
        print(f"   ‚ö†Ô∏è  Erreur de v√©rification: {e}")
    
    print("=" * 80)
    
    # √âTAPE 6 : Import
    print(f"\nüì• IMPORT DES DOCUMENTS")
    print("=" * 80)
    
    try:
        if mode == "upsert":
            from pymongo import UpdateOne
            
            print(f"Mode UPSERT: Mise √† jour ou insertion")
            
            operations = [
                UpdateOne(
                    {"id": doc["id"]},
                    {"$set": doc},
                    upsert=True
                )
                for doc in documents
            ]
            
            result = collection.bulk_write(operations, ordered=False)
            
            print(f"‚úì {result.upserted_count} documents ins√©r√©s")
            print(f"‚úì {result.modified_count} documents mis √† jour")
        
        else:  # insert
            print(f"Mode INSERT: Ignorer les doublons")
            
            inserted = 0
            duplicates = 0
            errors = 0
            
            for doc in documents:
                try:
                    collection.insert_one(doc)
                    inserted += 1
                except Exception as e:
                    if "duplicate key error" in str(e).lower():
                        duplicates += 1
                    else:
                        errors += 1
                        if errors <= 3:
                            print(f"   ‚ö†Ô∏è  Erreur: {str(e)[:100]}")
            
            print(f"‚úì {inserted} nouveaux documents ins√©r√©s")
            if duplicates > 0:
                print(f"‚ÑπÔ∏è  {duplicates} doublons ignor√©s")
            if errors > 0:
                print(f"‚úó {errors} erreurs")
    
    except Exception as e:
        print(f"‚úó Erreur d'import: {e}")
    
    print("=" * 80)
    
    # √âTAPE 7 : Statistiques finales
    print(f"\nüìä STATISTIQUES FINALES")
    print("=" * 80)
    
    try:
        total = collection.count_documents({})
        stats = db.command("collStats", "apec_raw")
        
        print(f"   - Total de documents : {total}")
        print(f"   - Taille de la collection : {stats.get('size', 0) / 1024:.2f} KB")
        print(f"   - Taille moyenne par document : {stats.get('avgObjSize', 0)} bytes")
        print(f"   - Nombre d'index : {stats.get('nindexes', 0)}")
        
        # Exemples
        print(f"\nüìÑ Exemples de documents (3 premiers) :")
        for doc in collection.find().limit(3):
            print(f"   ‚Ä¢ ID: {doc.get('id')[:20]}... | Ref: {doc.get('reference_apec')}")
    
    except Exception as e:
        print(f"   ‚ö†Ô∏è  Erreur stats: {e}")
    
    print("=" * 80)
    
    # Fermeture
    client.close()
    print(f"\n‚úì Connexion ferm√©e")
    
    print("\n" + "=" * 80)
    print("‚úì IMPORT TERMIN√â!")
    print("=" * 80)


def clean_collection(confirm_text: str = None):
    """
    Supprimer la collection apec_raw
    
    Args:
        confirm_text: Doit √™tre "OUI" pour confirmer
    """
    if confirm_text != "OUI":
        print("‚ö†Ô∏è  Suppression annul√©e")
        return
    
    print("\nüóëÔ∏è  SUPPRESSION DE LA COLLECTION")
    print("=" * 80)
    
    try:
        client = MongoClient(MONGO_URI, tlsCAFile=certifi.where())
        db = client[DB_NAME]
        
        count = db["apec_raw"].count_documents({})
        db["apec_raw"].drop()
        
        print(f"‚úì Collection 'apec_raw' supprim√©e ({count} documents)")
        print("=" * 80)
        
        client.close()
        
    except Exception as e:
        print(f"‚úó Erreur: {e}")


def main():
    """
    Fonction principale
    """
    
    # CONFIGURATION
    JSON_FILE_PATH = r"C:\Users\gopit\OneDrive\Documents\MASTER2SISE\Projet_NLP\RUCHE\output\data_cleaned.json"
    
    # Demander confirmation pour nettoyer
    print("\n" + "=" * 80)
    print("NETTOYAGE DE LA COLLECTION (OPTIONNEL)")
    print("=" * 80)
    print("\n‚ö†Ô∏è  Voulez-vous SUPPRIMER tous les documents de la collection 'apec_raw' ?")
    print("   (Utile si vous avez des donn√©es incorrectes √† remplacer)")
    choice = input("\n   Tapez 'OUI' pour confirmer la suppression, ou Enter pour ignorer: ")
    
    if choice == "OUI":
        clean_collection("OUI")
    
    # Lancer l'import
    import_to_apec_raw(
        json_file_path=JSON_FILE_PATH,
        mode="insert",  # Changer en "upsert" pour mettre √† jour les existants
        analyze_first=True
    )


if __name__ == "__main__":
    main()