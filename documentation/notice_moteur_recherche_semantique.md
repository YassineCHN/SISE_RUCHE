# Moteur de Recherche SÃ©mantique - Architecture et MÃ©thodologie

## Contexte du Module

Ce module implÃ©mente un **moteur de recherche sÃ©mantique** pour l'application RUCHE (Recherche UnifiÃ©e de CarriÃ¨res et d'HÃ©bergement d'Emplois). L'objectif est de permettre aux utilisateurs de rechercher des offres d'emploi en **langage naturel** plutÃ´t que par mots-clÃ©s stricts.

**ProblÃ©matique** : Les recherches traditionnelles par mots-clÃ©s (ex: "Data Engineer" AND "Lyon") sont **rigides** et gÃ©nÃ¨rent :
- **Faux nÃ©gatifs** : Une offre "IngÃ©nieur DonnÃ©es Ã  Lyon" ne sera pas trouvÃ©e (synonyme non dÃ©tectÃ©)
- **Faux positifs** : Une offre "Data Analyst Paris" pourrait matcher "Data" mÃªme si la localisation diffÃ¨re

**Solution proposÃ©e** : Un systÃ¨me de **recherche vectorielle** combinant :
1. **Embeddings sÃ©mantiques** : ReprÃ©sentation vectorielle dense capturant le sens des textes
2. **SimilaritÃ© cosinus** : Mesure de proximitÃ© sÃ©mantique dans l'espace vectoriel
3. **Compute pushdown** : Calcul cÃ´tÃ© SQL pour optimiser les performances

---

## RequÃªte "Fil Rouge"

Tout au long de cette fiche, nous suivrons le traitement de cette requÃªte utilisateur :

**Recherche** : _"Data Engineer Lyon"_

**Objectif** : Le systÃ¨me doit retourner les offres les plus pertinentes en comprenant :
- Le **rÃ´le** ("Data Engineer" = ingÃ©nieur donnÃ©es)
- La **localisation** ("Lyon")
- Les **synonymes** ("IngÃ©nieur DonnÃ©es", "Engineer Data", etc.)

**Offres fictives dans la base** :

| job_id | title | ville | type_contrat | description | Score attendu |
|--------|-------|-------|--------------|-------------|---------------|
| `job_001` | Data Engineer | Lyon | CDI | Construction de pipelines de donnÃ©es... | â­ **TrÃ¨s Ã©levÃ©** |
| `job_002` | IngÃ©nieur DonnÃ©es | Lyon | CDI | DÃ©veloppement d'architectures Big Data... | â­ **Ã‰levÃ©** (synonyme) |
| `job_003` | Data Analyst | Paris | CDI | Analyse de donnÃ©es business... | ğŸ”¸ **Moyen** (rÃ´le proche, lieu diffÃ©rent) |
| `job_004` | Boulanger | Lyon | CDI | Fabrication de pain et viennoiseries... | âŒ **TrÃ¨s faible** (aucun lien sÃ©mantique) |

---

# Phase 1 : Enrichissement SÃ©mantique (ETL Offline)

## Explication MÃ©thodologique

La premiÃ¨re phase consiste Ã  **gÃ©nÃ©rer des embeddings** (vecteurs sÃ©mantiques) pour chaque offre d'emploi. Contrairement Ã  une approche naÃ¯ve qui vectoriserait uniquement la description brute, nous adoptons une stratÃ©gie d'**enrichissement contextuel** via des jointures SQL.

**Pourquoi enrichir le contexte ?**

Un embedding gÃ©nÃ©rÃ© uniquement sur la description textuelle **perd des informations cruciales** :
- Le **type de contrat** (CDI vs Stage) influence la nature du poste
- La **localisation** (Paris vs Lyon) est un critÃ¨re discriminant
- Le **titre** et l'**entreprise** apportent un contexte sÃ©mantique fort

Le modÃ¨le doit comprendre le **contexte complet** de l'offre pour gÃ©nÃ©rer un embedding pertinent.

---

## Architecture Star Schema

Notre base de donnÃ©es suit un **schÃ©ma en Ã©toile** (Star Schema) optimisÃ© pour l'analytique :

```
         d_localisation              d_contrat
         â”œâ”€ id_ville (PK)            â”œâ”€ id_contrat (PK)
         â”œâ”€ ville                    â””â”€ type_contrat
         â””â”€ code_postal
                â”‚                          â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“    â†“
                        f_offre (Fact Table)
                        â”œâ”€ job_id (PK)
                        â”œâ”€ title
                        â”œâ”€ description
                        â”œâ”€ company_name
                        â”œâ”€ hard_skills
                        â”œâ”€ soft_skills
                        â”œâ”€ id_ville (FK) â”€â”€â†’ d_localisation
                        â”œâ”€ id_contrat (FK) â”€â”€â†’ d_contrat
                        â””â”€ embedding FLOAT[768]  â† Ã€ peupler
```

**Avantages du Star Schema** :
1. **Normalisation** : Ã‰vite la redondance (ville stockÃ©e une seule fois)
2. **Jointures simples** : Pas de jointures en cascade (snowflake)
3. **Performance** : OptimisÃ© pour les requÃªtes analytiques (DuckDB)

---

## StratÃ©gie de Jointure SQL

Pour gÃ©nÃ©rer un **document contexte enrichi**, nous effectuons des `LEFT JOIN` entre la table de fait et les dimensions :

```sql
SELECT 
    f.job_id,
    -- ConcatÃ©nation des champs pour enrichissement sÃ©mantique
    CONCAT_WS(' | ',
        f.title,                          -- "Data Engineer"
        f.company_name,                   -- "DataCorp"
        COALESCE(c.type_contrat, ''),    -- "CDI"
        COALESCE(l.ville, ''),            -- "Lyon"
        COALESCE(l.code_postal, ''),      -- "69001"
        f.description,                    -- "Construction de pipelines..."
        COALESCE(f.hard_skills, ''),      -- "Python, SQL, Spark"
        COALESCE(f.soft_skills, '')       -- "Travail en Ã©quipe"
    ) AS enriched_text
FROM f_offre f
LEFT JOIN d_localisation l ON f.id_ville = l.id_ville
LEFT JOIN d_contrat c ON f.id_contrat = c.id_contrat
WHERE f.description IS NOT NULL
```

**Pourquoi ces `LEFT JOIN` ?**

1. **`LEFT JOIN d_localisation`** :
   - RÃ©cupÃ¨re la ville en clair ("Lyon") au lieu de l'ID technique (42)
   - Le modÃ¨le comprendra mieux "Lyon" que "42"
   - `COALESCE(..., '')` gÃ¨re les valeurs `NULL` (offres sans localisation)

2. **`LEFT JOIN d_contrat`** :
   - RÃ©cupÃ¨re le type de contrat ("CDI", "Stage", "Alternance")
   - Ces termes ont une **charge sÃ©mantique forte** : "Stage Data Engineer" â‰  "CDI Data Engineer"

**SÃ©parateur `CONCAT_WS(' | ', ...)`** :
- `WS` = "With Separator" (sÃ©parateur personnalisÃ©)
- Le sÃ©parateur `|` Ã©vite l'ambiguÃ¯tÃ© entre champs adjacents
- Exemple sans sÃ©parateur : `"DataCorpCDILyon"` (illisible)
- Avec sÃ©parateur : `"DataCorp | CDI | Lyon"` (clair)

---

## Application au Fil Rouge

Pour l'offre **`job_001` (Data Engineer Ã  Lyon)** :

### DonnÃ©es brutes (tables sÃ©parÃ©es)

```sql
-- Table f_offre
job_id: "job_001"
title: "Data Engineer"
company_name: "DataCorp"
description: "Construction de pipelines de donnÃ©es pour..."
hard_skills: "Python, SQL, Apache Spark"
id_ville: 42        â† ClÃ© Ã©trangÃ¨re
id_contrat: 1       â† ClÃ© Ã©trangÃ¨re

-- Table d_localisation
id_ville: 42
ville: "Lyon"
code_postal: "69001"

-- Table d_contrat
id_contrat: 1
type_contrat: "CDI"
```

### Document enrichi aprÃ¨s jointure

```
enriched_text = "Data Engineer | DataCorp | CDI | Lyon | 69001 | 
                 Construction de pipelines de donnÃ©es pour ingÃ©rer, 
                 transformer et stocker des donnÃ©es massives. 
                 ExpÃ©rience avec Python, SQL, Apache Spark requise. | 
                 Python, SQL, Apache Spark | 
                 Travail en Ã©quipe, Autonomie"
```

**Analyse sÃ©mantique** :
- **Termes techniques** : "Data Engineer", "pipelines", "donnÃ©es massives", "Python", "Spark"
- **Localisation** : "Lyon", "69001"
- **Contrat** : "CDI"
- **Contexte** : Les mots-clÃ©s sont **dispersÃ©s** dans le texte, mais le modÃ¨le va apprendre les **relations sÃ©mantiques** entre eux

---

### Comparaison avec l'offre `job_004` (Boulanger)

```sql
-- Table f_offre
job_id: "job_004"
title: "Boulanger"
company_name: "Boulangerie Artisanale"
description: "Fabrication de pain et viennoiseries traditionnelles..."
hard_skills: "PÃ©trissage, Cuisson au four"
id_ville: 42        â† MÃªme ville (Lyon)
id_contrat: 1       â† MÃªme contrat (CDI)
```

```
enriched_text = "Boulanger | Boulangerie Artisanale | CDI | Lyon | 69001 | 
                 Fabrication de pain et viennoiseries traditionnelles. 
                 MaÃ®trise du pÃ©trissage et de la cuisson au four. | 
                 PÃ©trissage, Cuisson au four | 
                 Rigueur, Passion du mÃ©tier"
```

**Observation** : MÃªme ville, mÃªme contrat, mais **vocabulaire radicalement diffÃ©rent** ("boulanger", "pain", "pÃ©trissage" vs "data", "pipelines", "spark"). Le modÃ¨le va capturer cette diffÃ©rence sÃ©mantique.

---

# Phase 2 : Choix du ModÃ¨le d'Embeddings

## Explication MÃ©thodologique

Le choix du **modÃ¨le d'embeddings** est crucial : il dÃ©termine la qualitÃ© de la reprÃ©sentation vectorielle et donc la pertinence des rÃ©sultats.

### ModÃ¨le SÃ©lectionnÃ©

```python
model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-mpnet-base-v2')
```

**CaractÃ©ristiques techniques** :
- **Architecture** : MPNet (Masked Permuted Pre-training for Language Understanding)
- **Dimension** : 768 (768 dimensions par vecteur)
- **Multilinguisme** : EntraÃ®nÃ© sur 50+ langues dont franÃ§ais et anglais
- **Taille** : ~420 MB (modÃ¨le compact)

---

## Justification du Choix

### 1. Multilinguisme (FranÃ§ais + Anglais)

**Contexte RUCHE** : Les offres d'emploi contiennent :
- Du **franÃ§ais** : "IngÃ©nieur DonnÃ©es", "Stage", "Lyon"
- De l'**anglais** : "Data Engineer", "Machine Learning", "DevOps"
- Du **franglais** : "Lead Data Scientist", "Business Intelligence Analyst"

**ProblÃ¨me des modÃ¨les monolingues** :
- Un modÃ¨le franÃ§ais ne comprend pas "Data Engineer"
- Un modÃ¨le anglais ne comprend pas "IngÃ©nieur DonnÃ©es"

**Solution avec modÃ¨le multilingue** :
Le modÃ¨le a appris que "Data Engineer" (anglais) et "IngÃ©nieur DonnÃ©es" (franÃ§ais) sont **sÃ©mantiquement Ã©quivalents** grÃ¢ce Ã  un entraÃ®nement sur des corpus parallÃ¨les.

**Test empirique** :
```python
model.encode("Data Engineer")
# â†’ [0.234, -0.521, 0.789, ...]

model.encode("IngÃ©nieur DonnÃ©es")
# â†’ [0.231, -0.518, 0.791, ...]  â† Vecteurs trÃ¨s proches !

cosine_similarity(v1, v2) â‰ˆ 0.94  # Haute similaritÃ©
```

---

### 2. Dimension 768 : Compromis Performance/PrÃ©cision

**ThÃ©orie** : Plus la dimension est Ã©levÃ©e, plus le modÃ¨le peut capturer de nuances sÃ©mantiques.

**Dimensions courantes** :
| ModÃ¨le | Dimension | PrÃ©cision | Latence |
|--------|-----------|-----------|---------|
| all-MiniLM-L6-v2 | 384 | Bonne | Faible |
| **paraphrase-multilingual-mpnet-base-v2** | **768** | **TrÃ¨s bonne** | **ModÃ©rÃ©e** |
| all-mpnet-base-v2 | 768 | Excellente | ModÃ©rÃ©e |
| roberta-large | 1024 | Excellente | Ã‰levÃ©e |

**Choix de 768** :
- **SupÃ©rieur Ã  384** : Capture plus de nuances (utile pour distinguer "Data Analyst" vs "Data Engineer")
- **InfÃ©rieur Ã  1024** : Stockage raisonnable (768 Ã— 4 bytes = 3 KB par offre Ã— 5000 offres = 15 MB)
- **Performance** : Encodage de 1000 offres en ~30 secondes (CPU moderne)

---

### 3. EntraÃ®nement sur des Paraphrases

Le suffixe `paraphrase-*` indique que le modÃ¨le a Ã©tÃ© **fine-tunÃ©** sur des paires de phrases paraphrasÃ©es :

```
"Je cherche un Data Engineer Ã  Lyon"
â‰ˆ "Data Engineer basÃ© Ã  Lyon"
â‰ˆ "IngÃ©nieur DonnÃ©es rÃ©gion Lyonnaise"
```

**Avantage** : Le modÃ¨le comprend que ces phrases expriment la **mÃªme intention**, mÃªme avec des formulations diffÃ©rentes.

**Application RUCHE** :
```python
# RequÃªte utilisateur
query = "Data Engineer Lyon"

# Offre 1 (formulation proche)
offer_1 = "Data Engineer | DataCorp | CDI | Lyon | ..."
â†’ SimilaritÃ© attendue : ~0.85

# Offre 2 (formulation variÃ©e)
offer_2 = "IngÃ©nieur DonnÃ©es | TechCorp | CDI | Lyon | ..."
â†’ SimilaritÃ© attendue : ~0.78 (lÃ©gÃ¨rement infÃ©rieure mais toujours Ã©levÃ©e)
```

---

## Application au Fil Rouge

### Encodage du document enrichi (`job_001`)

```python
text = "Data Engineer | DataCorp | CDI | Lyon | 69001 | ..."

embedding = model.encode(text)
# Output: array de shape (768,)
# [0.234, -0.521, 0.789, 0.156, -0.923, ..., 0.412]
```

**InterprÃ©tation gÃ©omÃ©trique** :
- Le vecteur de 768 dimensions place l'offre dans un **espace sÃ©mantique**
- Des offres similaires (Data Engineer, Machine Learning Engineer) seront **proches** dans cet espace
- Des offres dissimilaires (Boulanger, Infirmier) seront **Ã©loignÃ©es**

---

### Visualisation Conceptuelle (Projection 2D)

En rÃ©alitÃ©, l'espace est 768D, mais conceptuellement :

```
           Axe "Technique Data/IA"
                    â†‘
                    â”‚
          Data      â”‚     ML
        Engineer â—  â”‚  â— Engineer
                    â”‚
     Data Analyst â— â”‚
                    â”‚
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Axe "Localisation"
                    â”‚                Paris
                  Lyon
                    â”‚
                    â”‚  â— Boulanger
                    â”‚  â— Infirmier
                    â†“
```

**Observation** : "Data Engineer Lyon" sera proche de "Data Analyst Lyon" (mÃªme localisation, domaine proche) mais Ã©loignÃ© de "Boulanger Lyon" (localisation identique mais domaine totalement diffÃ©rent).

---

# Phase 3 : StratÃ©gie de Stockage dans MotherDuck

## Explication MÃ©thodologique

Les embeddings gÃ©nÃ©rÃ©s (768 dimensions par offre) doivent Ãªtre stockÃ©s efficacement pour permettre des recherches rapides. Nous utilisons **MotherDuck** (DuckDB cloud) avec un typage fort.

### SchÃ©ma SQL

```sql
ALTER TABLE f_offre 
ADD COLUMN embedding FLOAT[768];
```

**Type `FLOAT[768]`** :
- **`FLOAT`** : Type numÃ©rique Ã  virgule flottante (32 bits)
- **`[768]`** : Array de taille fixe (768 Ã©lÃ©ments)
- **Stockage** : 768 Ã— 4 bytes = **3072 bytes (3 KB)** par offre

---

## Avantages du PrÃ©-calcul (Offline)

### Architecture : Offline vs Online

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  OFFLINE (ETL - Une fois)                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  1. Extraction (SQL JOIN)                                  â”‚
â”‚     f_offre + d_localisation + d_contrat                   â”‚
â”‚     â†“                                                       â”‚
â”‚  2. Enrichissement                                          â”‚
â”‚     Document contexte complet                               â”‚
â”‚     â†“                                                       â”‚
â”‚  3. Vectorisation (Sentence Transformer)                   â”‚
â”‚     768D embedding                                          â”‚
â”‚     â†“                                                       â”‚
â”‚  4. Stockage (MotherDuck)                                  â”‚
â”‚     UPDATE f_offre SET embedding = [...]                   â”‚
â”‚                                                             â”‚
â”‚  DurÃ©e: ~2 min pour 5000 offres                           â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ONLINE (Recherche - Ã€ chaque requÃªte)                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  1. Encodage de la requÃªte utilisateur                     â”‚
â”‚     "Data Engineer Lyon" â†’ embedding 768D                   â”‚
â”‚     DurÃ©e: ~50 ms                                          â”‚
â”‚     â†“                                                       â”‚
â”‚  2. Calcul similaritÃ© (SQL Server-side)                    â”‚
â”‚     array_cosine_similarity(f.embedding, query_emb)        â”‚
â”‚     DurÃ©e: ~100-200 ms (5000 offres)                       â”‚
â”‚     â†“                                                       â”‚
â”‚  3. Tri + TOP 50                                           â”‚
â”‚     ORDER BY similarity DESC LIMIT 50                       â”‚
â”‚                                                             â”‚
â”‚  DurÃ©e totale: ~150-250 ms                                 â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Justification** :
1. **Latence utilisateur** : Encodage + recherche < 300 ms (acceptable)
2. **Pas de recalcul** : Les embeddings des offres sont **figÃ©s** (mis Ã  jour nuitamment si nouvelles offres)
3. **ScalabilitÃ©** : Si 50 000 offres, la latence reste ~1-2s (linÃ©aire en O(n))

---

## Code Python (ETL)

```python
class EmbeddingETL:
    def update_embeddings(self, df: pd.DataFrame):
        """
        Met Ã  jour les embeddings dans MotherDuck
        
        StratÃ©gie:
        1. CrÃ©er table temporaire avec embeddings
        2. UPDATE par JOIN (efficace, 1 seule requÃªte)
        3. Nettoyage
        """
        # CrÃ©er table temporaire
        self.con.execute(f"""
            CREATE TEMP TABLE temp_embeddings (
                job_id TEXT PRIMARY KEY,
                embedding FLOAT[{self.embedding_dim}]  -- FLOAT[768]
            )
        """)
        
        # Convertir embeddings numpy â†’ liste Python
        df_copy = df.copy()
        df_copy['embedding'] = df_copy['embedding'].apply(lambda x: x.tolist())
        
        # Insertion par batch (1000 offres)
        for i in tqdm(range(0, len(df_copy), 1000)):
            batch = df_copy.iloc[i:i+1000]
            self.con.execute("INSERT INTO temp_embeddings SELECT * FROM batch")
        
        # UPDATE par JOIN (1 seule requÃªte SQL)
        self.con.execute("""
            UPDATE f_offre f
            SET embedding = t.embedding
            FROM temp_embeddings t
            WHERE f.job_id = t.job_id
        """)
        
        # Nettoyage
        self.con.execute("DROP TABLE temp_embeddings")
```

**Avantages de l'UPDATE par JOIN** :
- **1 seule requÃªte** au lieu de 5000 UPDATE individuels
- **Transactionnel** : Soit tout passe, soit rien (atomicitÃ©)
- **Performances** : ~10-15s pour 5000 offres (vs plusieurs minutes en UPDATE unitaires)

---

## Application au Fil Rouge

### Stockage de l'embedding `job_001`

```sql
-- AprÃ¨s ETL
SELECT job_id, embedding
FROM f_offre
WHERE job_id = 'job_001';

-- RÃ©sultat
job_id: "job_001"
embedding: [0.234, -0.521, 0.789, ..., 0.412]  -- 768 valeurs
```

**VÃ©rification d'intÃ©gritÃ©** :
```sql
-- Compter les offres avec embedding
SELECT COUNT(*) FROM f_offre WHERE embedding IS NOT NULL;
-- Output: 4377 (toutes les offres Data/IA)

-- VÃ©rifier la dimension
SELECT array_length(embedding) FROM f_offre LIMIT 1;
-- Output: 768
```

---

# Phase 4 : Processus de Recherche (Online)

## Explication MÃ©thodologique

Lorsqu'un utilisateur lance une recherche, le systÃ¨me doit :
1. **Encoder** la requÃªte utilisateur en embedding 768D
2. **Calculer** la similaritÃ© entre ce vecteur et tous les embeddings stockÃ©s
3. **Trier** par score dÃ©croissant et retourner les TOP-K rÃ©sultats

La clÃ© de l'optimisation rÃ©side dans le **compute pushdown** : dÃ©lÃ©guer le calcul au moteur SQL.

---

## Ã‰tape 1 : Encodage de la RequÃªte

### Code Python

```python
def semantic_search(query: str, model, top_k=50):
    # Encoder la requÃªte utilisateur
    query_embedding = model.encode(query, convert_to_numpy=True)
    # Output: array de shape (768,)
    
    # Convertir en liste Python pour DuckDB
    embedding_list = query_embedding.tolist()
    # Output: [0.123, -0.456, 0.789, ...]
```

### Application au Fil Rouge

```python
query = "Data Engineer Lyon"

query_embedding = model.encode(query)
# [0.221, -0.534, 0.801, 0.143, ..., 0.398]
#  â†‘ 768 valeurs
```

**DurÃ©e** : ~50 ms (CPU moderne)

---

## Ã‰tape 2 : Calcul de SimilaritÃ© (Compute Pushdown)

### Concept : Server-side vs Client-side

#### âŒ Approche Client-side (NaÃ¯ve)

```python
# RÃ©cupÃ©rer TOUS les embeddings en Python
query = "SELECT job_id, embedding FROM f_offre"
results = con.execute(query).fetchdf()  # 4377 lignes Ã— 768 colonnes

# Calculer similaritÃ© en Python
similarities = []
for idx, row in results.iterrows():
    sim = cosine_similarity(query_embedding, row['embedding'])
    similarities.append((row['job_id'], sim))

# Trier
similarities.sort(key=lambda x: x[1], reverse=True)
top_results = similarities[:50]
```

**ProblÃ¨mes** :
1. **Transfert rÃ©seau** : 4377 Ã— 3 KB = **13 MB** de donnÃ©es transfÃ©rÃ©es (MotherDuck â†’ Python)
2. **RAM Python** : 13 MB chargÃ©s en mÃ©moire
3. **Latence** : Transfert + calcul Python = **1-2 secondes**
4. **ScalabilitÃ©** : Si 50 000 offres â†’ 150 MB transfÃ©rÃ©s !

---

#### âœ… Approche Server-side (Compute Pushdown)

```python
# Calcul DANS MotherDuck (SQL)
query_sql = f"""
SELECT 
    f.job_id,
    f.title,
    l.ville,
    c.type_contrat,
    -- Calcul de similaritÃ© cÃ´tÃ© SQL
    array_cosine_similarity(
        f.embedding,              -- Vecteur stockÃ© (768D)
        ?::FLOAT[768]            -- Vecteur de la requÃªte (paramÃ¨tre)
    ) AS similarity_score
FROM f_offre f
LEFT JOIN d_localisation l ON f.id_ville = l.id_ville
LEFT JOIN d_contrat c ON f.id_contrat = c.id_contrat
WHERE f.embedding IS NOT NULL
ORDER BY similarity_score DESC
LIMIT {top_k}
"""

results = con.execute(query_sql, [embedding_list]).fetchdf()
# Retourne SEULEMENT les 50 meilleurs rÃ©sultats
```

**Avantages** :
1. **Transfert minimal** : Seulement 50 lignes Ã— ~1 KB = **50 KB** (vs 13 MB)
2. **Calcul optimisÃ©** : DuckDB utilise du C++ vectorisÃ© (SIMD)
3. **Latence** : ~100-200 ms (vs 1-2 secondes)
4. **ScalabilitÃ©** : Latence quasi-linÃ©aire en O(n)

---

### Formule MathÃ©matique : SimilaritÃ© Cosinus

Pour deux vecteurs $\mathbf{u}$ et $\mathbf{v}$ de dimension 768 :

$$
\text{cosine\_similarity}(\mathbf{u}, \mathbf{v}) = \frac{\mathbf{u} \cdot \mathbf{v}}{||\mathbf{u}|| \times ||\mathbf{v}||} = \frac{\sum_{i=1}^{768} u_i \times v_i}{\sqrt{\sum_{i=1}^{768} u_i^2} \times \sqrt{\sum_{i=1}^{768} v_i^2}}
$$

**PropriÃ©tÃ©s** :
- **Domaine** : $[-1, 1]$
  - $+1$ : Vecteurs identiques (parfaite similaritÃ©)
  - $0$ : Vecteurs orthogonaux (aucune similaritÃ©)
  - $-1$ : Vecteurs opposÃ©s (anti-similaritÃ©)
- **IndÃ©pendant de la norme** : Seule la **direction** compte, pas la magnitude
- **SymÃ©trique** : $\cos(\mathbf{u}, \mathbf{v}) = \cos(\mathbf{v}, \mathbf{u})$

---

### ImplÃ©mentation DuckDB

DuckDB fournit la fonction native `array_cosine_similarity()` :

```sql
array_cosine_similarity(
    array1: FLOAT[N],
    array2: FLOAT[N]
) â†’ FLOAT
```

**Exemple** :
```sql
SELECT array_cosine_similarity(
    [1.0, 0.0, 0.0],
    [1.0, 0.0, 0.0]
);
-- Output: 1.0 (vecteurs identiques)

SELECT array_cosine_similarity(
    [1.0, 0.0],
    [0.0, 1.0]
);
-- Output: 0.0 (vecteurs orthogonaux)
```

---

## Ã‰tape 3 : Filtres Hybrides (NLP + SQL)

Le systÃ¨me combine **recherche sÃ©mantique** (NLP) et **filtres SQL** (localisation, contrat) :

```python
where_clauses = ["f.embedding IS NOT NULL"]

if ville_filter == "Lyon":
    where_clauses.append("l.ville = 'Lyon'")

if contrat_filter == "CDI":
    where_clauses.append("c.type_contrat = 'CDI'")

where_sql = " AND ".join(where_clauses)
# â†’ "f.embedding IS NOT NULL AND l.ville = 'Lyon' AND c.type_contrat = 'CDI'"
```

**RequÃªte SQL complÃ¨te** :
```sql
SELECT 
    f.job_id,
    f.title,
    l.ville,
    c.type_contrat,
    array_cosine_similarity(f.embedding, ?::FLOAT[768]) AS similarity_score
FROM f_offre f
LEFT JOIN d_localisation l ON f.id_ville = l.id_ville
LEFT JOIN d_contrat c ON f.id_contrat = c.id_contrat
WHERE 
    f.embedding IS NOT NULL 
    AND l.ville = 'Lyon'        -- Filtre SQL
    AND c.type_contrat = 'CDI'  -- Filtre SQL
ORDER BY similarity_score DESC  -- Tri NLP
LIMIT 50
```

**Architecture hybride** :
1. **Filtres SQL** : RÃ©duisent le pool (4377 offres â†’ 200 offres Ã  Lyon)
2. **SimilaritÃ© NLP** : Trie les 200 offres par pertinence sÃ©mantique
3. **TOP-K** : Retourne les 50 meilleures

**Avantage** : Performances optimales (~50 ms au lieu de 200 ms)

---

# Phase 5 : InterprÃ©tation des RÃ©sultats

## Application au Fil Rouge

### RequÃªte : "Data Engineer Lyon"

```python
query = "Data Engineer Lyon"
query_embedding = model.encode(query)
# [0.221, -0.534, 0.801, 0.143, ..., 0.398]
```

---

### Calcul de SimilaritÃ© pour Chaque Offre

#### Offre `job_001` : Data Engineer (Lyon)

```python
# Document enrichi (Phase 1)
doc_001 = "Data Engineer | DataCorp | CDI | Lyon | 69001 | 
           Construction de pipelines de donnÃ©es pour..."

# Embedding (Phase 3)
emb_001 = [0.234, -0.521, 0.789, 0.156, ..., 0.412]
```

**Calcul** :
$$
\text{sim}(query, job\_001) = \frac{query \cdot emb\_001}{||query|| \times ||emb\_001||}
$$

En supposant que les embeddings sont **normalisÃ©s** (norme = 1), le calcul se simplifie :
$$
\text{sim} = query \cdot emb\_001 = \sum_{i=1}^{768} q_i \times e_i
$$

```python
# Produit scalaire (simplifiÃ© pour illustration)
similarity = (
    0.221 Ã— 0.234 +    # Dimension 1
    -0.534 Ã— -0.521 +  # Dimension 2
    0.801 Ã— 0.789 +    # Dimension 3
    ...                # 765 autres dimensions
    0.398 Ã— 0.412      # Dimension 768
)
# â‰ˆ 0.87 (score Ã©levÃ©)
```

**InterprÃ©tation** : Score de **0.87 (87%)** indique une **trÃ¨s haute similaritÃ©**.

---

#### Offre `job_002` : IngÃ©nieur DonnÃ©es (Lyon)

```python
doc_002 = "IngÃ©nieur DonnÃ©es | TechCorp | CDI | Lyon | 69002 | 
           DÃ©veloppement d'architectures Big Data..."

emb_002 = [0.218, -0.509, 0.776, 0.141, ..., 0.389]
```

**Calcul** :
$$
\text{sim}(query, job\_002) \approx 0.82
$$

**InterprÃ©tation** : Score de **0.82 (82%)** lÃ©gÃ¨rement infÃ©rieur Ã  `job_001` car :
- Terme "IngÃ©nieur DonnÃ©es" (franÃ§ais) vs "Data Engineer" (anglais)
- Le modÃ¨le comprend la **synonymie** mais privilÃ©gie la correspondance exacte

---

#### Offre `job_003` : Data Analyst (Paris)

```python
doc_003 = "Data Analyst | BizCorp | CDI | Paris | 75001 | 
           Analyse de donnÃ©es business pour..."

emb_003 = [0.198, -0.487, 0.712, 0.133, ..., 0.351]
```

**Calcul** :
$$
\text{sim}(query, job\_003) \approx 0.65
$$

**InterprÃ©tation** : Score de **0.65 (65%)** modÃ©rÃ© car :
- **RÃ´le proche** : "Data Analyst" vs "Data Engineer" (domaine Data)
- **Localisation diffÃ©rente** : "Paris" vs "Lyon" (pÃ©nalitÃ© sÃ©mantique)

---

#### Offre `job_004` : Boulanger (Lyon)

```python
doc_004 = "Boulanger | Boulangerie Artisanale | CDI | Lyon | 69001 | 
           Fabrication de pain et viennoiseries..."

emb_004 = [-0.023, 0.156, -0.089, 0.021, ..., -0.102]
```

**Calcul** :
$$
\text{sim}(query, job\_004) \approx 0.12
$$

**InterprÃ©tation** : Score de **0.12 (12%)** trÃ¨s faible car :
- **Aucun lien sÃ©mantique** : "Boulanger" vs "Data Engineer"
- **Vocabulaire disjoint** : "pain", "pÃ©trissage" vs "donnÃ©es", "pipelines"
- Seule correspondance : **"Lyon"** (insuffisant)

---

### Classement Final (TOP 50)

```sql
SELECT 
    job_id, 
    title, 
    ville,
    ROUND(similarity_score * 100, 1) AS score_pct
FROM results
ORDER BY similarity_score DESC
LIMIT 4;
```

**RÃ©sultat** :
| Rang | job_id | title | ville | score_pct |
|------|--------|-------|-------|-----------|
| 1 | job_001 | Data Engineer | Lyon | **87.0%** |
| 2 | job_002 | IngÃ©nieur DonnÃ©es | Lyon | **82.0%** |
| 3 | job_003 | Data Analyst | Paris | **65.0%** |
| ... | ... | ... | ... | ... |
| 2341 | job_004 | Boulanger | Lyon | **12.0%** |

**Analyse** :
- `job_001` et `job_002` : **TOP 2** (mÃªme ville, mÃªme domaine)
- `job_003` : Rang moyen (domaine proche, ville diffÃ©rente)
- `job_004` : **TrÃ¨s bas** (aucun lien sÃ©mantique)

---

## Visualisation GÃ©omÃ©trique (Projection 2D)

```
              Score de SimilaritÃ©
                    â”‚
                1.0 â”‚  â— job_001 (Data Engineer Lyon)
                    â”‚  â— job_002 (IngÃ©nieur DonnÃ©es Lyon)
                    â”‚
                0.8 â”‚
                    â”‚
                0.6 â”‚          â— job_003 (Data Analyst Paris)
                    â”‚
                0.4 â”‚
                    â”‚
                0.2 â”‚
                    â”‚                             â— job_004 (Boulanger Lyon)
                0.0 â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’
                       Distance SÃ©mantique Ã  la RequÃªte
```

---

### Optimisations Futures

1. **Index HNSW (Hierarchical Navigable Small World)** :
   - Recherche approximative en O(log n) au lieu de O(n)
   - DuckDB ne supporte pas nativement (alternative : FAISS, Pinecone)

2. **Quantization** :
   - RÃ©duire 768D â†’ 384D ou 256D
   - Trade-off : -20% prÃ©cision, +50% vitesse

3. **Caching** :
   - Mettre en cache les requÃªtes frÃ©quentes ("Data Scientist Paris")
   - Redis ou Memcached cÃ´tÃ© serveur

---

# RÃ©fÃ©rences Bibliographiques

## Embeddings et Sentence Transformers

1. **Reimers, N., & Gurevych, I. (2019)**  
   *"Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks"*  
   EMNLP 2019.  

2. **Reimers, N., & Gurevych, I. (2020)**  
   *"Making Monolingual Sentence Embeddings Multilingual using Knowledge Distillation"*  
   EMNLP 2020.  

## SimilaritÃ© Cosinus et Recherche Vectorielle

3. **Salton, G., & McGill, M. J. (1983)**  
   *Introduction to Modern Information Retrieval*  
   McGraw-Hill.  

4. **Johnson, J., Douze, M., & JÃ©gou, H. (2019)**  
   *"Billion-scale similarity search with GPUs"*  
   IEEE Transactions on Big Data.  

## Star Schema et Data Warehousing

5. **Kimball, R., & Ross, M. (2013)**  
   *The Data Warehouse Toolkit: The Definitive Guide to Dimensional Modeling (3rd ed.)*  
   Wiley.  

## DuckDB et Compute Pushdown

6. **Raasveldt, M., & MÃ¼hleisen, H. (2019)**  
   *"DuckDB: an Embeddable Analytical Database"*  
   SIGMOD 2019.  
---

**Auteurs** : Ã‰quipe RUCHE  
**Date** : Janvier 2026  
**Version** : 1.0