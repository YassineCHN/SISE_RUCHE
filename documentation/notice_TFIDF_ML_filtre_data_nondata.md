# Classification d'Offres d'Emploi Data/IA par TF-IDF et R√©gression Logistique


## Contexte du module

Ce module vise √† **automatiser le filtrage d'offres d'emploi** pour distinguer les offres r√©ellement li√©s √† la Data Science, l'Intelligence Artificielle, et l'ing√©nierie des donn√©es, des postes p√©riph√©riques (commercial, RH, sant√©, etc.). 

**Probl√©matique** : Les termes "Data", "IA", "Analytics" apparaissent dans de nombreuses offres sans √™tre des postes techniques (ex : "Business Developer IA", "Commercial Data"). Une approche purement lexicale (regex) g√©n√®re des **faux positifs**.

**Solution propos√©e** : Un syst√®me hybride combinant :

1. **Regex** pour cr√©er un jeu d'entra√Ænement supervis√©
2. **TF-IDF** pour la repr√©sentation vectorielle du texte
3. **R√©gression Logistique** pour la classification binaire

## Offre d'emploi "Fil Rouge" 

Tout au long de cette fiche, nous allons suivre le traitement de cette offre :

**Titre** : _Business Developer Grands Comptes ‚Äì SaaS & IA (B2B) F/H_  
**Description** : _Notre client est un √©diteur fran√ßais de logiciels SaaS B2B... Le poste : Dans le cadre de la structuration de son d√©veloppement commercial, notre client recrute un Commercial Grands Comptes SaaS B2B H/F._  
**Comp√©tences** : _Vente de solutions logicielles, Autonomie, Anglais_

**Pi√®ge** : Le terme "IA" est pr√©sent dans le titre, ce qui pourrait d√©clencher une d√©tection positive avec une approche regex na√Øve.  
**Objectif** : Le mod√®le doit d√©tecter que c'est un poste **Commercial** et le classer comme **Non-Data** (label = 0).

**Particularit√© importante** : Cette offre n'a √©t√© d√©tect√©e **ni par la whitelist ni par la blacklist** (unlabeled), ce qui rend ce cas d'usage **encore plus int√©ressant** car il d√©montre la capacit√© de **g√©n√©ralisation du ML** au-del√† des r√®gles regex explicites.

---

# Phase 1 : Pr√©paration des Donn√©es d'Entra√Ænement

## Explication M√©thodologique

La premi√®re phase consiste √† **cr√©er un jeu de donn√©es supervis√©** √† partir d'une approche non supervis√©e (regex). On utilise des r√®gles expertes pour g√©n√©rer automatiquement des labels qui serviront √† entra√Æner un mod√®le plus robuste.

**Pourquoi cette approche ?**

- Les **patterns regex** capturent des connaissances expertes (ex : "data scientist" est un indicateur fort)
- Mais ils sont **rigides** et ne g√©n√©ralisent pas bien (ex : "ing√©nieur donn√©es" pourrait ne pas √™tre captur√©)
- Le ML permettra d'**apprendre des patterns plus complexes** (combinaisons de termes, contexte)

**Concepts cl√©s** :

- **Whitelist** : Patterns indiquant un poste Data/IA
- **Blacklist** : Patterns excluant un poste (sant√©, commerce, etc.)
- **Labellisation binaire** : 1 = Data, 0 = Non-Data, None = Non labellis√©

---

## Pseudo-code

```
POUR chaque offre dans dataset:
    texte_combin√© = titre + description + fonction
    
    SI texte_combin√© MATCH whitelist_patterns ET NON blacklist_patterns:
        label = 1 (Data job)
    
    SINON SI texte_combin√© MATCH blacklist_patterns ET NON whitelist_patterns:
        label = 0 (Non-Data job)
    
    SINON:
        label = None (√† pr√©dire par ML)

SEPARER:
    - labeled_data = offres avec label d√©fini
    - unlabeled_data = offres sans label (√† pr√©dire)
```

---

## Notre Code

```python
# Patterns Whitelist (indicateurs de postes Data/IA)
whitelist_patterns = [
    r'\bdata\s*scientist\b', r'\bdata\s*analyst\b', r'\bdata\s*engineer\b',
    r'\bmachine\s+learning\b', r'\bml\s+engineer\b', r'\bdeep\s+learning\b',
    r'\bintelligence\s+artificielle\b', r'\bai\s+engineer\b',
    r'\bbig\s*data\b', r'\bhadoop\b', r'\bspark\b',
    r'\bbusiness\s+intelligence\b', r'\b\bbi\b.*\b(analyst|engineer|developer)\b',
    r'\banalytics\b', r'\bdata.*analytics\b',
    # ... (15 patterns au total)
]

# Patterns Blacklist (indicateurs de postes NON Data)
blacklist_patterns = [
    r'\binfirmier\b', r'\bm[√©e]decin\b',
    r'\bcomptable\b(?!.*(data|analyste))',  # Sauf si "comptable data"
    r'\bcommercial\b(?!.*(data|tech|software|saas))',  # ‚ö†Ô∏è Pattern probl√©matique
    r'\btechnico[- ]commercial\b(?!.*(data|it))',
    r'\bgestionnaire.*paie\b(?!.*(data|analytics|sirh))',
    # ... (15 patterns au total)
]

# Cr√©ation du texte combin√©
df['combined_text'] = (
    df['title'].fillna('') + ' ' + 
    df['description'].fillna('') + ' ' +
    df['job_function'].fillna('')
).str.lower()

# Application des patterns
whitelist_mask = df['combined_text'].str.contains(
    '|'.join(whitelist_patterns), regex=True, case=False, na=False
)
blacklist_mask = df['combined_text'].str.contains(
    '|'.join(blacklist_patterns), regex=True, case=False, na=False
)

# Labellisation
df['ml_label'] = None
df.loc[whitelist_mask & ~blacklist_mask, 'ml_label'] = 1  # Data
df.loc[blacklist_mask & ~whitelist_mask, 'ml_label'] = 0  # Non-Data

# S√©paration
labeled_data = df[df['ml_label'].notna()].copy()
unlabeled_data = df[df['ml_label'].isna()].copy()
```

---

## Interpr√©tation du "Fil Rouge" 

Pour l'offre **"Business Developer Grands Comptes ‚Äì SaaS & IA (B2B)"** :

### √âtape 1 : Concat√©nation du texte
```python
combined_text = "business developer grands comptes saas ia b2b notre client 
                 est un √©diteur fran√ßais de logiciels saas b2b le poste dans 
                 le cadre de la structuration de son d√©veloppement commercial 
                 notre client recrute un commercial grands comptes saas b2b 
                 vente de solutions logicielles autonomie anglais"
```

### √âtape 2 : Test des patterns

**Whitelist** :

- ‚ùå `\bintelligence\s+artificielle\b` ‚Üí **NON D√âTECT√â** (le texte contient "ia" mais pas "intelligence artificielle")
- ‚ùå Le terme "IA" seul **n'est pas dans la whitelist** (trop ambigu, risque de faux positifs)
- **R√©sultat** : `whitelist_mask = False`

**Blacklist** :

- ‚ö†Ô∏è Pattern test√© : `\bcommercial\b(?!.*(data|tech|software|saas))`
- Le texte contient bien "commercial" dans "...d√©veloppement commercial notre client recrute un commercial grands comptes..."
- **Probl√®me du lookahead n√©gatif** : `(?!.*(data|tech|software|saas))` cherche ces termes **apr√®s** "commercial" dans le reste du texte
- Dans notre texte : `"...commercial grands comptes saas b2b..."`
- Le terme "saas" appara√Æt **apr√®s** "commercial" ‚Üí Le lookahead n√©gatif **√©choue** (car il trouve "saas")
- **R√©sultat** : `blacklist_mask = False` ‚ùå (le pattern ne matche pas √† cause du lookahead n√©gatif)

### √âtape 3 : Labellisation

```python
# Whitelist : False
# Blacklist : False
# ‚Üí Ni l'un ni l'autre

df.loc[whitelist_mask & ~blacklist_mask, 'ml_label'] = 1  # Non applicable
df.loc[blacklist_mask & ~whitelist_mask, 'ml_label'] = 0  # Non applicable

# R√©sultat : ml_label reste √† None
```

**Label final** : `ml_label = None` ‚Üí **UNLABELED** ‚ùå

**Verdict** : L'offre n'est **pas labellis√©e** par les regex. Elle fera partie des **3418 offres unlabeled** (52.5%) qui seront trait√©es par le mod√®le ML en Phase 7.

---

### R√©sultats de la Phase 1 (avec localisation de notre offre)

Notre offre "Business Developer" fait partie des **3418 unlabeled** :

```
Data split:
  Total offers: 6506
  ‚îú‚îÄ Labeled (from regex): 3088 (47.5%)
  ‚îÇ  ‚îú‚îÄ Data jobs (whitelist): 2611
  ‚îÇ  ‚îî‚îÄ Non-Data jobs (blacklist): 477
  ‚îî‚îÄ Unlabeled (to predict): 3418 (52.5%)  ‚¨ÖÔ∏è NOTRE OFFRE EST ICI
      ‚îî‚îÄ Dont "Business Developer SaaS & IA"

Class balance:
  Ratio (minority/majority): 0.18
    ‚ö†Ô∏è Imbalanced! Using class_weight='balanced'
```

**Observation critique** : Le pattern blacklist `\bcommercial\b(?!.*(data|tech|software|saas))` est **trop restrictif**. Il exclut les postes commerciaux dans des contextes SaaS/tech, alors que ces postes ne sont **pas** des postes Data/IA techniques. C'est une **limite des regex** qui sera compens√©e par le ML.

---

### Analyse d'Erreur du Pattern Regex

#### Pourquoi la Blacklist n'a-t-elle PAS d√©tect√© notre offre ?

**Pattern utilis√©** :
```python
r'\bcommercial\b(?!.*(data|tech|software|saas))'
```

**D√©composition** :

- `\bcommercial\b` : D√©tecte le mot "commercial" (avec fronti√®res de mots)
- `(?!.*(data|tech|software|saas))` : **Lookahead n√©gatif** qui v√©rifie que RIEN apr√®s "commercial" ne contient ces termes

**Test sur notre texte** :

```
"...d√©veloppement commercial notre client recrute un commercial grands comptes saas b2b..."
                   ‚Üë
                   Position o√π "commercial" est d√©tect√©
                   
Lookahead v√©rifie : "notre client recrute un commercial grands comptes saas b2b..."
                                                                          ‚Üë
                                                                     "saas" trouv√© !
                                                                     
‚Üí Lookahead n√©gatif √âCHOUE
‚Üí Pattern ne matche PAS
‚Üí L'offre n'est PAS blacklist√©e
```

**Intention originale du pattern** : Exclure les postes commerciaux **sauf** s'ils sont dans un contexte tech/data.

**Exemples voulus** :

- ‚úÖ "Commercial automobile" ‚Üí Blacklist (d√©tect√©)
- ‚úÖ "Commercial immobilier" ‚Üí Blacklist (d√©tect√©)
- ‚ùå "Commercial Data SaaS" ‚Üí PAS blacklist (car "data" et "saas" apr√®s)

**Probl√®me** : Dans notre cas, "saas" appara√Æt **bien apr√®s** "commercial" dans le texte, mais le poste reste un **vrai commercial**, pas un poste Data. Le lookahead n√©gatif emp√™che la d√©tection alors qu'elle serait souhaitable.

**Solutions alternatives** :

**Option 1** : Pattern sans lookahead (plus simple)
```python
r'\bcommercial\b'  # D√©tecte tout "commercial"
```

**Option 2** : Pattern avec contexte imm√©diat uniquement
```python
r'\bcommercial\b(?!\s+(data|tech|software))'  # V√©rifie seulement le mot suivant
```

**Option 3** : Laisser le ML g√©rer les cas ambigus ‚úÖ **(Approche retenue)**
```python
# Ne pas essayer de tout g√©rer avec regex
# Utiliser regex pour les cas √©vidents
# Laisser ML pr√©dire les cas limites
```

---

# Phase 2 : Feature Engineering (TF-IDF)

## Explication M√©thodologique

Le **TF-IDF (Term Frequency-Inverse Document Frequency)** est une technique de repr√©sentation vectorielle qui transforme du texte en nombres tout en capturant l'importance s√©mantique des mots.

### Formule math√©matique

Pour un terme $t$ dans un document $d$ parmi $N$ documents :

$$
\text{TF-IDF}(t, d) = \text{TF}(t, d) \times \text{IDF}(t)
$$

O√π :
- **TF (Term Frequency)** : Fr√©quence du terme dans le document
  $$
  \text{TF}(t, d) = \frac{\text{nombre d'occurrences de } t \text{ dans } d}{\text{nombre total de termes dans } d}
  $$

- **IDF (Inverse Document Frequency)** : Mesure la raret√© du terme dans le corpus
  $$
  \text{IDF}(t) = \log\left(\frac{N}{\text{nombre de documents contenant } t}\right)
  $$

### Intuition

- Un mot **fr√©quent** dans un document mais **rare** dans le corpus aura un score √©lev√© (discriminant)
- Un mot **tr√®s fr√©quent partout** (ex : "le", "de") aura un score faible (non discriminant)
- Les **stopwords** (mots vides) sont retir√©s avant le calcul

### Param√®tres de notre TF-IDF

```python
TfidfVectorizer(
    max_features=500,           # Garde les 500 termes les plus importants
    max_df=0.7,                 # Ignore les termes pr√©sents dans >70% des docs
    min_df=2,                   # Ignore les termes pr√©sents dans <2 docs
    stop_words=french_stopwords, # 157 stopwords fran√ßais
    ngram_range=(1, 2),         # Unigrams (1 mot) + Bigrams (2 mots)
    lowercase=True,
    strip_accents='unicode'
)
```

**Pourquoi des bigrams ?**  
Les bigrams capturent des **expressions compos√©es** comme "data scientist", "intelligence artificielle", "business developer" qui ont une s√©mantique propre, diff√©rente des mots isol√©s.

---

## Pseudo-code

```
vectorizer = TF-IDF(max_features=500, ngrams=(1,2), stopwords=French)

POUR chaque document dans labeled_data:
    1. Tokenisation (s√©paration en mots)
    2. Suppression des stopwords ("le", "de", "un"...)
    3. Calcul TF (fr√©quence locale)
    4. Calcul IDF (raret√© globale)
    5. Produit TF √ó IDF
    6. Normalisation L2 (vecteur unitaire)

RESULTAT: Matrice sparse (3088 documents √ó 500 features)
```

---

## Notre Code

```python
from sklearn.feature_extraction.text import TfidfVectorizer

# Initialisation du vectorizer
vectorizer = TfidfVectorizer(
    max_features=500,
    max_df=0.7,
    min_df=2,
    stop_words=french_stopwords,
    ngram_range=(1, 2),
    lowercase=True,
    strip_accents='unicode'
)

# Transformation sur donn√©es labellis√©es uniquement
X_labeled = vectorizer.fit_transform(labeled_data['combined_text'])
y_labeled = labeled_data['ml_label'].astype(int).values

print(f"TF-IDF matrix shape: {X_labeled.shape}")
print(f"Features extracted: {len(vectorizer.get_feature_names_out())}")
print(f"Sparsity: {(1 - X_labeled.nnz / np.prod(X_labeled.shape)) * 100:.1f}%")
```

**Sortie** :
```
TF-IDF matrix shape: (3088, 500)
Features extracted: 500
Sparsity: 85.4%
```

**Interpr√©tation de la sparsit√©** : 85.4% des valeurs sont nulles. C'est normal en NLP : chaque document ne contient qu'une petite fraction du vocabulaire total.

---

## Interpr√©tation du "Fil Rouge"

Pour l'offre **"Business Developer"**, le vectorizer extrait :

### Unigrams (mots simples)
- `commercial` : TF-IDF √©lev√© (terme fr√©quent dans ce document, rare dans le corpus Data)
- `business` : TF-IDF √©lev√©
- `vente` : TF-IDF √©lev√©
- `d√©veloppement` : TF-IDF mod√©r√© (ambigu : d√©veloppement logiciel vs d√©veloppement commercial)
- `saas` : TF-IDF mod√©r√© (contexte B2B)

### Bigrams (expressions de 2 mots)
- `business developer` : **TF-IDF tr√®s √©lev√©** (expression discriminante)
- `commercial grands` : TF-IDF √©lev√©
- `grands comptes` : TF-IDF √©lev√©
- `solutions logicielles` : TF-IDF mod√©r√©

### Termes absents ou faibles
- `data`, `scientist`, `engineer`, `python`, `machine learning` : **TF-IDF = 0** (absents)
- `ia` : TF-IDF faible (pr√©sent 1 fois, tr√®s fr√©quent dans le corpus ‚Üí IDF faible)

**Repr√©sentation vectorielle simplifi√©e** (6 features sur 500) :
```python
[
    ('commercial', 0.45),
    ('business developer', 0.62),  # Bigram le plus discriminant
    ('vente', 0.38),
    ('grands comptes', 0.35),
    ('saas', 0.21),
    ('ia', 0.08)  # Faible car tr√®s fr√©quent dans le corpus
]
```

**Conclusion** : Le vecteur TF-IDF de cette offre est **fortement orient√©** vers les termes commerciaux. Le mod√®le va apprendre que ces features sont corr√©l√©es √† la classe "Non-Data".

---

# Phase 3 : Entra√Ænement du Mod√®le (R√©gression Logistique)

## Explication M√©thodologique

La **R√©gression Logistique** est un algorithme de classification binaire qui mod√©lise la probabilit√© d'appartenance √† une classe en fonction des features.

### Principe math√©matique

Pour un vecteur de features $\mathbf{x} = (x_1, ..., x_{500})$ (nos 500 features TF-IDF), le mod√®le calcule :

$$
P(y=1 | \mathbf{x}) = \sigma(\mathbf{w}^T \mathbf{x} + b) = \frac{1}{1 + e^{-(\mathbf{w}^T \mathbf{x} + b)}}
$$

O√π :

- $\sigma$ : Fonction sigmo√Øde (transforme $\mathbb{R}$ en $[0, 1]$)
- $\mathbf{w} = (w_1, ..., w_{500})$ : Poids (coefficients) appris par le mod√®le
- $b$ : Biais (intercept)

### Interpr√©tation des coefficients

- $w_i > 0$ : La feature $i$ augmente la probabilit√© d'√™tre un poste Data
- $w_i < 0$ : La feature $i$ diminue la probabilit√© (indicateur Non-Data)
- $|w_i|$ √©lev√© : Feature tr√®s discriminante

### Gestion du d√©s√©quilibre de classes

Avec un ratio 0.18 (477 Non-Data / 2611 Data), le mod√®le standard serait biais√© vers la classe majoritaire. Le param√®tre `class_weight='balanced'` ajuste automatiquement les poids :

$$
\text{weight}_{\text{class } c} = \frac{n_{\text{samples}}}{n_{\text{classes}} \times n_{\text{samples classe } c}}
$$

---

## Pseudo-code

```
# Split train/validation
X_train, X_val, y_train, y_val = Split(X_labeled, y_labeled, test_size=0.2)

# Initialisation du mod√®le
model = LogisticRegression(
    class_weight='balanced',  # Compense le d√©s√©quilibre
    max_iter=1000,
    solver='liblinear'        # Optimiseur adapt√© aux petits datasets
)

# Entra√Ænement
model.fit(X_train, y_train)

# Optimisation par maximum de vraisemblance :
# Minimiser: -Œ£ [y_i * log(p_i) + (1-y_i) * log(1-p_i)]
#            + Œª * ||w||‚ÇÇ  (r√©gularisation L2)
```

---

## Notre Code

```python
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split, cross_val_score

# Split stratifi√© (conserve la proportion des classes)
X_train, X_val, y_train, y_val = train_test_split(
    X_labeled, y_labeled, 
    test_size=0.2,  # 20% validation
    random_state=42,
    stratify=y_labeled  # ‚ö†Ô∏è Important pour le d√©s√©quilibre
)

# Initialisation
model = LogisticRegression(
    class_weight='balanced',
    max_iter=1000,
    random_state=42,
    solver='liblinear'
)

# Entra√Ænement
model.fit(X_train, y_train)

# Cross-validation (5 folds)
cv_scores = cross_val_score(model, X_labeled, y_labeled, cv=5, scoring='f1')
print(f"Mean F1: {cv_scores.mean():.3f} ¬± {cv_scores.std():.3f}")
```

**Sortie** :
```
Train/Validation split:
  Training set: 2470 samples
    ‚îú‚îÄ Data jobs: 2088
    ‚îî‚îÄ Non-Data jobs: 382
  Validation set: 618 samples
    ‚îú‚îÄ Data jobs: 523
    ‚îî‚îÄ Non-Data jobs: 95

5-Fold Cross-Validation:
  F1 scores: [0.982, 0.976, 0.986, 0.965, 0.981]
  Mean F1: 0.978 ¬± 0.007
```

**Interpr√©tation** :

- F1-Score moyen de **97.8%** : excellente performance
- Faible √©cart-type (**¬±0.7%**) : mod√®le stable, pas de surapprentissage
- Les 5 folds ont des performances similaires ‚Üí bonne g√©n√©ralisation

---

## Interpr√©tation du "Fil Rouge"

Le mod√®le a appris les coefficients suivants (extraits pertinents pour notre offre) :

```python
# Coefficients positifs (indicateurs Data)
w['data scientist'] = +2.225
w['engineer'] = +2.970
w['intelligence artificielle'] = +2.682

# Coefficients n√©gatifs (indicateurs Non-Data)
w['commercial'] = -6.047  ‚ö†Ô∏è Poids le plus n√©gatif !
w['business'] = -1.599
w['vente'] = (estim√© -2.5, non affich√© dans top 15)
```

**Note importante** : Bien que notre offre "Business Developer" n'ait **pas √©t√© vue** dans les donn√©es d'entra√Ænement (elle est unlabeled), le mod√®le a appris des **patterns g√©n√©raux** √† partir d'autres offres commerciales d√©tect√©es par la blacklist. Ces patterns seront appliqu√©s en Phase 7.

---

# Phase 4 : √âvaluation du Mod√®le

## Explication M√©thodologique

L'√©valuation d'un mod√®le de classification n√©cessite plusieurs m√©triques compl√©mentaires, surtout en pr√©sence de **classes d√©s√©quilibr√©es**.

### M√©triques utilis√©es

#### 1. **Precision** (Pr√©cision)
$$
\text{Precision} = \frac{TP}{TP + FP}
$$
*Sur les offres pr√©dites Data, quelle proportion est r√©ellement Data ?*

#### 2. **Recall** (Rappel / Sensibilit√©)
$$
\text{Recall} = \frac{TP}{TP + FN}
$$
*Sur les offres r√©ellement Data, quelle proportion est d√©tect√©e ?*

#### 3. **F1-Score**
$$
\text{F1} = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}
$$
*Moyenne harmonique entre Precision et Recall (√©quilibre)*

#### 4. **ROC-AUC**

- **ROC** : Courbe TPR (True Positive Rate) vs FPR (False Positive Rate)
- **AUC** : Aire sous la courbe (1 = parfait, 0.5 = al√©atoire)

---

## Notre Code

```python
from sklearn.metrics import classification_report, roc_auc_score

# Pr√©dictions
y_val_pred = model.predict(X_val)
y_val_proba = model.predict_proba(X_val)[:, 1]  # Probabilit√©s classe 1

# Classification Report
print(classification_report(
    y_val, y_val_pred, 
    target_names=['Non-Data', 'Data'],
    digits=3
))

# ROC-AUC
roc_auc = roc_auc_score(y_val, y_val_proba)
print(f"ROC-AUC Score: {roc_auc:.3f}")
```

**Sortie** :
```
Classification Report (Validation Set):
              precision    recall  f1-score   support

    Non-Data      0.886     0.979     0.930        95
        Data      0.996     0.977     0.986       523

    accuracy                          0.977       618
   macro avg      0.941     0.978     0.958       618
weighted avg      0.979     0.977     0.978       618

ROC-AUC Score: 0.996
```

---

## Analyse des R√©sultats

### Classe "Data" (majoritaire)

- **Precision = 99.6%** : Presque aucun faux positif (offres Non-Data class√©es Data par erreur)
- **Recall = 97.7%** : Le mod√®le d√©tecte 97.7% des vrais postes Data
- **F1 = 0.986** : Excellent √©quilibre

### Classe "Non-Data" (minoritaire)

- **Precision = 88.6%** : 11.4% de faux positifs (offres Data class√©es Non-Data)
- **Recall = 97.9%** : Le mod√®le d√©tecte 97.9% des vrais postes Non-Data
- **F1 = 0.930** : Tr√®s bon score malgr√© le d√©s√©quilibre

### ROC-AUC = 0.996
**Quasi-parfait** : Le mod√®le discrimine excellemment les deux classes sur toute la plage de seuils de probabilit√©.

---

# Phase 5 : Interpr√©tabilit√© du Mod√®le

## Explication M√©thodologique

L'**interpr√©tabilit√©** est cruciale en ML pour :

1. Comprendre les d√©cisions du mod√®le
2. Valider la coh√©rence avec l'expertise m√©tier
3. D√©tecter d'√©ventuels biais
4. Communiquer les r√©sultats aux parties prenantes

La R√©gression Logistique est un mod√®le **intrins√®quement interpr√©table** : chaque coefficient $w_i$ quantifie l'influence de la feature $i$ sur la d√©cision.

### Coefficient $w_i$ et Odds Ratio

Le coefficient $w_i$ est li√© √† l'**Odds Ratio** :
$$
\text{OR}(x_i) = e^{w_i}
$$

**Interpr√©tation** :

- Si $w_i = +2.0$ : Multiplier $x_i$ par 1 augmente les odds de 7.4√ó (‚âà $e^2$)
- Si $w_i = -6.0$ : Multiplier $x_i$ par 1 diminue les odds de 400√ó (‚âà $e^{-6}$)

---

## Notre Code

```python
# Extraction des features et coefficients
feature_names = vectorizer.get_feature_names_out()
coefficients = model.coef_[0]  # Shape: (500,)

# Tri par valeur absolue
feature_importance = pd.DataFrame({
    'feature': feature_names,
    'coefficient': coefficients
}).sort_values('coefficient', ascending=False)

# Top 15 positifs (indicateurs Data)
print("üîµ Top 15 POSITIVE features (Data job indicators):")
for idx, row in feature_importance.head(15).iterrows():
    print(f"  {row['feature']:30s} ‚Üí {row['coefficient']:+.3f}")

# Top 15 n√©gatifs (indicateurs Non-Data)
print("\nüî¥ Top 15 NEGATIVE features (Non-Data job indicators):")
for idx, row in feature_importance.tail(15).iterrows():
    print(f"  {row['feature']:30s} ‚Üí {row['coefficient']:+.3f}")
```

**Sortie** :
```
üîµ Top 15 POSITIVE features (Data job indicators):
  donnees                        ‚Üí +4.178
  intelligence                   ‚Üí +3.013
  engineer                       ‚Üí +2.970
  data engineer                  ‚Üí +2.883
  data analyst                   ‚Üí +2.851
  analyst                        ‚Üí +2.819
  artificielle                   ‚Üí +2.687
  intelligence artificielle      ‚Üí +2.682
  bi                             ‚Üí +2.542
  solutions                      ‚Üí +2.427
  scientist                      ‚Üí +2.239
  data scientist                 ‚Üí +2.225
  metiers                        ‚Üí +1.928
  analytics                      ‚Üí +1.898
  br                             ‚Üí +1.807

üî¥ Top 15 NEGATIVE features (Non-Data job indicators):
  commercial                     ‚Üí -6.047  ‚ö†Ô∏è Le plus discriminant !
  comptable                      ‚Üí -4.581
  sante                          ‚Üí -2.176
  formation                      ‚Üí -1.830
  maintenance                    ‚Üí -1.678
  gestion                        ‚Üí -1.643
  business                       ‚Üí -1.599  ‚ö†Ô∏è Pertinent pour notre cas
  participation                  ‚Üí -1.456
  entretien                      ‚Üí -1.275
  prise                          ‚Üí -1.192
  etc                            ‚Üí -1.076
  specialise                     ‚Üí -1.044
  accompagner                    ‚Üí -0.976
  affaires                       ‚Üí -0.916
  tres                           ‚Üí -0.907
```

---

## Analyse des Features

### Features positives (Data)

- **Termes techniques** : `engineer`, `analyst`, `scientist`, `bi`, `analytics`
- **Domaine IA** : `intelligence`, `artificielle`, `intelligence artificielle`
- **Technologies** : `donnees`, `solutions`, `br` (Business Requirements ?)

### Features n√©gatives (Non-Data)

- **Commerce** : `commercial` (-6.047 !), `business` (-1.599), `affaires` (-0.916)
- **Fonctions support** : `comptable`, `gestion`, `formation`, `maintenance`
- **Sant√©** : `sante` (-2.176)

**Coh√©rence m√©tier** : Les coefficients refl√®tent bien la r√©alit√© :

- Un poste avec "commercial" a **400√ó moins de chances** d'√™tre Data qu'un poste sans ce terme
- Un poste avec "data engineer" a **17√ó plus de chances** d'√™tre Data

---

# Phase 7 : Pr√©diction sur Donn√©es Non Labellis√©es

## Explication M√©thodologique

Le mod√®le entra√Æn√© est maintenant appliqu√© aux **3418 offres non labellis√©es** (52.5% du jeu de donn√©es initial). Ces offres n'ont √©t√© match√©es ni par la whitelist ni par la blacklist :

- Elles contiennent peut-√™tre des termes ambigus
- Ou des formulations non couvertes par les regex

Le ML permet de **g√©n√©raliser au-del√† des patterns regex** et de r√©cup√©rer des offres Data qui auraient √©t√© perdues.

**C'EST ICI que notre offre "Business Developer" est trait√©e** : le mod√®le n'a **jamais vu** d'exemple similaire dans les donn√©es d'entra√Ænement (puisque la blacklist ne l'a pas d√©tect√©e). Il doit donc **g√©n√©raliser** uniquement sur la base des patterns TF-IDF appris.

---

## Notre Code

```python
# Transformation TF-IDF sur donn√©es non labellis√©es
X_unlabeled = vectorizer.transform(unlabeled_data['combined_text'])

# Pr√©diction
unlabeled_pred = model.predict(X_unlabeled)
unlabeled_proba = model.predict_proba(X_unlabeled)[:, 1]

# Ajout des r√©sultats
unlabeled_data['ml_prediction'] = unlabeled_pred
unlabeled_data['ml_probability'] = unlabeled_proba

print(f"Prediction results:")
print(f"  Predicted as Data: {(unlabeled_pred==1).sum()} ({(unlabeled_pred==1).sum()/len(unlabeled_data)*100:.1f}%)")
print(f"  Predicted as Non-Data: {(unlabeled_pred==0).sum()}")
```

**Sortie** :
```
Predicting on 3418 unlabeled offers...

Prediction results:
  Predicted as Data: 1766 (51.7%)
  Predicted as Non-Data: 1652 (48.3%)

Probability statistics:
  Mean probability (Data class): 0.487
  Median probability: 0.522
  Std probability: 0.284
```

---

## Analyse des Pr√©dictions

### Offres √† haute confiance (Data, p > 0.9)
```
‚Ä¢ D√©veloppeur Java F/H                                         (p=0.912)
‚Ä¢ Lead Developer Java - √âcosyst√®me Cloud et IA F/H             (p=0.981)
‚Ä¢ DevOps Engineer F/H                                          (p=0.909)
‚Ä¢ Consultant Senior - Tech lead Data Science & IA - F/H        (p=0.906)
```
‚Üí **Postes techniques** : d√©veloppeurs, ing√©nieurs, DevOps, Tech leads

### Offres √† haute confiance (Non-Data, p < 0.1)
```
‚Ä¢ Charg√© d'affaire maintenance outillages F/H                  (p=0.086)
‚Ä¢ Business Developer Grands Comptes ‚Äì SaaS & IA (B2B) F/H      (p=0.025) ‚ö†Ô∏è NOTRE CAS
‚Ä¢ Gestionnaire RH ADP F/H                                      (p=0.096)
‚Ä¢ Commercial Grands Comptes F/H                                (p=0.021)
‚Ä¢ Responsable Comptable F/H                                    (p=0.030)
```
‚Üí **Postes non techniques** : commercial, RH, gestion, comptabilit√©

---

## Interpr√©tation du "Fil Rouge" 

### Contexte
Notre offre fait partie des **3418 unlabeled**. Le mod√®le n'a **jamais vu** d'exemple similaire dans les donn√©es d'entra√Ænement (puisque la blacklist n'a pas d√©tect√© les "commercial + saas"). Le mod√®le doit donc **g√©n√©raliser** en se basant uniquement sur ce qu'il a appris des patterns TF-IDF.

### Vecteur TF-IDF de l'offre "Business Developer"

```python
x = {
    'commercial': 0.45,           # Tr√®s discriminant
    'business': 0.30,             # Discriminant
    'business developer': 0.62,   # Bigram tr√®s discriminant
    'vente': 0.38,                # Tr√®s discriminant
    'saas': 0.21,                 # Contexte B2B
    'grands comptes': 0.35,       # Contexte commercial
    'ia': 0.08,                   # Faible (tr√®s fr√©quent dans corpus)
    'logicielles': 0.15,          # Contexte tech mais ambigu
    # ... 492 autres features √† 0
}
```

### Coefficients du mod√®le (appris en Phase 3)

```python
w = {
    'commercial': -6.047,         # ‚ö†Ô∏è TR√àS N√âGATIF
    'business': -1.599,           # N√©gatif
    'business developer': -2.5,   # Estim√© n√©gatif (pas dans top 15)
    'vente': -2.5,                # Estim√© n√©gatif
    'saas': +0.5,                 # L√©g√®rement positif (ambigu)
    'ia': +0.3,                   # L√©g√®rement positif
    # ...
}
```

### Calcul du score logit

$$
z = \mathbf{w}^T \mathbf{x} + b
$$

**D√©composition des contributions** :

| Feature | TF-IDF (x) | Coefficient (w) | Contribution (w√óx) |
|---------|------------|-----------------|-------------------|
| `commercial` | 0.45 | -6.047 | **-2.72** ‚ö†Ô∏è |
| `business developer` | 0.62 | -2.5 | **-1.55** |
| `business` | 0.30 | -1.599 | -0.48 |
| `vente` | 0.38 | -2.5 | -0.95 |
| `grands comptes` | 0.35 | -1.5 | -0.53 |
| `saas` | 0.21 | +0.5 | +0.10 |
| `logicielles` | 0.15 | +0.3 | +0.05 |
| `ia` | 0.08 | +0.3 | +0.02 |

**Somme des contributions principales** : 
$$
z \approx -2.72 - 1.55 - 0.48 - 0.95 - 0.53 + 0.10 + 0.05 + 0.02 + b
$$
$$
z \approx -6.06 + b
$$

En supposant $b \approx 0$ (car le mod√®le est bien calibr√©), on obtient :
$$
z \approx -6.0
$$

### Calcul de la probabilit√©

$$
P(y=1 | \mathbf{x}) = \sigma(z) = \frac{1}{1 + e^{-z}} = \frac{1}{1 + e^{6.0}} \approx \frac{1}{1 + 403} \approx 0.0025
$$

### R√©sultat observ√© dans les logs

```
  Sample predictions (High confidence Non-Data jobs):
  ‚Ä¢ Business Developer Grands Comptes ‚Äì SaaS & IA (B2B) F/H      (p=0.025)
```

**Probabilit√© r√©elle** : **2.5%** (l√©g√®rement sup√©rieure √† notre calcul car d'autres features contribuent)

---

## Analyse Approfondie

### Pourquoi le mod√®le a-t-il r√©ussi ?

1. **Dominance du terme "commercial"** :

   - Coefficient : -6.047 (le plus n√©gatif du mod√®le)
   - TF-IDF : 0.45 (tr√®s pr√©sent dans ce document)
   - Contribution : -2.72 (**domine tout le calcul**)

2. **Renforcement par les bigrams** :

   - "business developer" est un **bigram** appris par le TF-IDF
   - Le mod√®le a vu d'autres offres avec "business developer" dans les **477 Non-Data** labellis√©es
   - Coefficient estim√© : -2.5 (n√©gatif)

3. **Termes positifs trop faibles** :

   - "ia" : TF-IDF faible (0.08) car **tr√®s fr√©quent dans le corpus**
   - "saas" : Terme ambigu (peut appara√Ætre dans offres Data et Non-Data)
   - Les contributions positives (+0.17 au total) ne compensent **pas** les n√©gatives (-6.23)

### Comparaison avec un vrai poste Data

```
Consultant Senior - Tech lead Data Science & IA - F/H  (p=0.906)
```

**Vecteur TF-IDF (simplifi√©)** :
```python
x = {
    'data science': 0.72,      # Bigram tr√®s fort
    'tech lead': 0.58,         # Contexte technique
    'consultant': 0.35,        # Contexte conseil
    'senior': 0.28,            # Exp√©rience
    'ia': 0.08                 # M√™me valeur que Business Developer
}
```

**Calcul simplifi√©** :
$$
z \approx (+2.225 \times 0.72) + (+2.0 \times 0.58) + ... \approx +2.8
$$
$$
P(y=1) = \sigma(+2.8) \approx 0.94
$$

**Diff√©rence clef** : La pr√©sence de termes **fortement positifs** ("data science", "tech lead") domine le calcul, m√™me avec le m√™me "ia" pr√©sent.

### Le mod√®le n'a PAS √©t√© tromp√©

Malgr√© :

- La pr√©sence de "IA" dans le titre
- La pr√©sence de "SaaS" (contexte tech)
- La mention de "solutions logicielles"
- **L'absence de labellisation par regex** (unlabeled) ‚Üê **Point clef**

Le mod√®le a **correctement identifi√©** que c'est un poste **Commercial** (Non-Data) avec **97.5% de confiance**.

### Capacit√© de G√©n√©ralisation

**C'est LE point fort du ML** :

- Le mod√®le n'a **jamais vu** cet exemple exact dans l'entra√Ænement
- Les regex ont **√©chou√©** √† le d√©tecter
- Mais en apprenant les **patterns g√©n√©raux** (poids des termes), le mod√®le a su extrapoler

**Preuve empirique** :

- 1766 offres unlabeled pr√©dites comme Data (51.7%)
- 1652 offres unlabeled pr√©dites comme Non-Data (48.3%)
- Notre offre fait partie des **50 plus confiantes Non-Data** (p < 0.1)

---

# Phase 8 : Filtrage Final et M√©triques Globales

## Explication M√©thodologique

La derni√®re √©tape consiste √† **combiner** :

1. Les offres d√©tect√©es par **regex** (whitelist) : 2611 offres Data
2. Les offres pr√©dites par **ML** (non labellis√©es) : 1766 offres Data

Cette approche hybride permet de :

- **Conserver** les offres √©videntes (d√©tect√©es par regex)
- **R√©cup√©rer** les offres ambigu√´s (d√©tect√©es par ML)
- **√âliminer** les faux positifs (d√©tect√©s par blacklist ou ML)

---

## Notre Code

```python
# Offres Data issues du regex
data_from_regex = labeled_data[labeled_data['ml_label'] == 1].copy()

# Offres Data pr√©dites par ML
data_from_ml = unlabeled_data[unlabeled_data['ml_prediction'] == 1].copy()

# Combinaison
df_filtered = pd.concat([data_from_regex, data_from_ml], ignore_index=True)

print(f"Final filtering results:")
print(f"  Initial records: {initial_count}")
print(f"  ‚îú‚îÄ Regex Data jobs kept: {len(data_from_regex)}")
print(f"  ‚îú‚îÄ ML-predicted Data jobs kept: {len(data_from_ml)}")
print(f"  ‚îî‚îÄ Total kept: {len(df_filtered)}")
print(f"  Removed: {initial_count - len(df_filtered)} ({(initial_count - len(df_filtered))/initial_count*100:.1f}%)")
print(f"  Retention rate: {len(df_filtered)/initial_count*100:.1f}%")
```

**Sortie** :
```
Final filtering results:
  Initial records: 6506
  ‚îú‚îÄ Regex Data jobs kept: 2611
  ‚îú‚îÄ ML-predicted Data jobs kept: 1766
  ‚îî‚îÄ Total kept: 4377
  Removed: 2129 (32.7%)
  Retention rate: 67.3%
```

## Bilan Final

### Avant filtrage

- **6506 offres** brutes (tous types confondus)

### Apr√®s filtrage hybride (Regex + ML)

- **4377 offres Data/IA** conserv√©es (67.3%)
- **2129 offres Non-Data** √©limin√©es (32.7%)

### Apport du ML

- **1766 offres Data r√©cup√©r√©es** (27% du total final)
- Ces offres n'auraient **pas √©t√© d√©tect√©es** par regex seul
- **Gain de ~40%** par rapport √† une approche purement regex (2611 ‚Üí 4377)

### Performance du mod√®le

- **F1-Score : 0.978**
- **ROC-AUC : 0.996**
- **Pr√©cision sur classe Data : 99.6%**


### R√©sultat

- **2611 offres** d√©tect√©es par regex (cas √©vidents)
- **1766 offres** r√©cup√©r√©es par ML (cas ambigus)
- **Gain total** : +67.6% par rapport √† du regex seul.

---

# R√©f√©rences Bibliographiques

## Articles Fondateurs

### TF-IDF
1. **Salton, G., & McGill, M. J. (1983)**  
   *Introduction to Modern Information Retrieval*  
   McGraw-Hill.  

2. **Sparck Jones, K. (1972)**  
   *"A statistical interpretation of term specificity and its application in retrieval"*  
   Journal of Documentation, 28(1), 11-21.  

### R√©gression Logistique
3. **Cox, D. R. (1958)**  
   *"The regression analysis of binary sequences"*  
   Journal of the Royal Statistical Society: Series B, 20(2), 215-232.  

4. **Hosmer, D. W., Lemeshow, S., & Sturdivant, R. X. (2013)**  
   *Applied Logistic Regression (3rd ed.)*  
   Wiley.  

### Classification de Textes
5. **Joachims, T. (1998)**  
   *"Text categorization with support vector machines: Learning with many relevant features"*  
   European Conference on Machine Learning (pp. 137-142). Springer.  

6. **Sebastiani, F. (2002)**  
   *"Machine learning in automated text categorization"*  
   ACM Computing Surveys, 34(1), 1-47.  

### Gestion du D√©s√©quilibre de Classes
7. **He, H., & Garcia, E. A. (2009)**  
   *"Learning from imbalanced data"*  
   IEEE Transactions on Knowledge and Data Engineering, 21(9), 1263-1284.  

8. **Chawla, N. V., Bowyer, K. W., Hall, L. O., & Kegelmeyer, W. P. (2002)**  
   *"SMOTE: Synthetic minority over-sampling technique"*  
   Journal of Artificial Intelligence Research, 16, 321-357.  

## Ressources en Ligne
9. **Scikit-learn Documentation**  
   https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html  

10. **Scikit-learn: Logistic Regression**  
    https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html  

11. **Manning, C. D., Raghavan, P., & Sch√ºtze, H. (2008)**  
    *Introduction to Information Retrieval*  
    Cambridge University Press.  
    ‚Üí Livre de r√©f√©rence en NLP, disponible gratuitement en ligne :  
    https://nlp.stanford.edu/IR-book/

---

**Auteur** : RUCHE's Team  
